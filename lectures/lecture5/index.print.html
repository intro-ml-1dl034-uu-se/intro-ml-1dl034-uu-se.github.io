<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.123.3">
    <meta name="generator" content="Relearn 5.24.2+tip">
    <meta name="description" content="">
    <meta name="author" content="Justin Pearson">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Lecture 5: Support Vector Machines :: Introduction to ML 1D034 homepage.">
    <meta name="twitter:description" content="Today&rsquo;s topic Support Vector Machines (SVM) Support vector machines (SVMs) are used for classification, and use some of the ideas from logistic regression. Support vector machines deal with noisy data, where some labels are miss-classified, with large-margin classifiers.
Support vector machines can also do non-linear classification using kernels. A kernel is a non-linear transformation of the input data into a higher dimensional space. Kernels transform your input data into a space where it is possible to do linear separation as in logistic regression.">
    <meta property="og:title" content="Lecture 5: Support Vector Machines :: Introduction to ML 1D034 homepage.">
    <meta property="og:description" content="Today&rsquo;s topic Support Vector Machines (SVM) Support vector machines (SVMs) are used for classification, and use some of the ideas from logistic regression. Support vector machines deal with noisy data, where some labels are miss-classified, with large-margin classifiers.
Support vector machines can also do non-linear classification using kernels. A kernel is a non-linear transformation of the input data into a higher dimensional space. Kernels transform your input data into a space where it is possible to do linear separation as in logistic regression.">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://intro-ml-1dl034-uu-se.github.io/lectures/lecture5/index.html">
    <meta property="article:section" content="Lectures :: Introduction to ML 1D034 homepage.">
    <meta property="og:site_name" content="Introduction to ML 1D034 homepage.">
    <title>Lecture 5: Support Vector Machines :: Introduction to ML 1D034 homepage.</title>
    <link href="https://intro-ml-1dl034-uu-se.github.io/lectures/lecture5/index.html" rel="canonical" type="text/html" title="Lecture 5: Support Vector Machines :: Introduction to ML 1D034 homepage.">
    <link href="/lectures/lecture5/index.xml" rel="alternate" type="application/rss+xml" title="Lecture 5: Support Vector Machines :: Introduction to ML 1D034 homepage.">
    <!-- https://github.com/filamentgroup/loadCSS/blob/master/README.md#how-to-use -->
    <link href="/css/fontawesome-all.min.css?1709192834" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/css/fontawesome-all.min.css?1709192834" rel="stylesheet"></noscript>
    <link href="/css/nucleus.css?1709192834" rel="stylesheet">
    <link href="/css/auto-complete.css?1709192834" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/css/auto-complete.css?1709192834" rel="stylesheet"></noscript>
    <link href="/css/perfect-scrollbar.min.css?1709192834" rel="stylesheet">
    <link href="/css/fonts.css?1709192834" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/css/fonts.css?1709192834" rel="stylesheet"></noscript>
    <link href="/css/theme.css?1709192834" rel="stylesheet">
    <link href="/css/theme-blue.css?1709192834" rel="stylesheet" id="R-variant-style">
    <link href="/css/chroma-learn.css?1709192834" rel="stylesheet" id="R-variant-chroma-style">
    <link href="/css/variant.css?1709192834" rel="stylesheet">
    <link href="/css/print.css?1709192834" rel="stylesheet" media="print">
    <link href="/css/format-print.css?1709192834" rel="stylesheet">
    <link href="/css/ie.css?1709192834" rel="stylesheet">
    <script src="/js/url.js?1709192834"></script>
    <script src="/js/variant.js?1709192834"></script>
    <script>
      // hack to let hugo tell us how to get to the root when using relativeURLs, it needs to be called *url= for it to do its magic:
      // https://github.com/gohugoio/hugo/blob/145b3fcce35fbac25c7033c91c1b7ae6d1179da8/transform/urlreplacers/absurlreplacer.go#L72
      window.index_js_url="/index.search.js";
      var root_url="/";
      var baseUri=root_url.replace(/\/$/, '');
      window.relearn = window.relearn || {};
      window.relearn.baseUriFull='https:\/\/intro-ml-1dl034-uu-se.github.io/';
      // variant stuff
      window.relearn.themeVariantModifier='';
      window.variants && variants.init( [ 'blue' ] );
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
    </script>
  </head>
  <body class="mobile-support print" data-url="/lectures/lecture5/index.html">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
          </div>
          <ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype="http://schema.org/BreadcrumbList"><li
            itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><a itemprop="item" href="/index.html"><span itemprop="name">Introduction to Machine Learning 1DL034</span></a><meta itemprop="position" content="1">&nbsp;>&nbsp;</li><li
            itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><a itemprop="item" href="/lectures/index.html"><span itemprop="name">Lectures</span></a><meta itemprop="position" content="2">&nbsp;>&nbsp;</li><li
            itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><span itemprop="name">Lecture 5: Support Vector Machines</span><meta itemprop="position" content="3"></li>
          </ol>
          <div class="topbar-area topbar-area-end" data-area="end">
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable default" tabindex="-1">
        <div class="flex-block-wrapper">
          <article class="default">
            <header class="headline">
            </header>
<h1 id="lecture-5-support-vector-machines">Lecture 5: Support Vector Machines</h1>

<h2 id="todays-topic-support-vector-machines-svm">Today&rsquo;s topic Support Vector Machines (SVM)</h2>
<p>Support vector machines (SVMs) are used for classification, and use
some of the ideas from logistic regression.  Support vector machines
deal with noisy data, where some labels are miss-classified, with
<em>large-margin classifiers</em>.</p>
<p>Support vector machines can also do non-linear classification using
<em>kernels</em>. A kernel is a non-linear transformation of the input data
into a higher dimensional space. Kernels transform your input data
into a space where it is possible to do linear separation as in
logistic regression.</p>
<p>This sounds very abstract, but the basic mathematics is not very
complicated.  Support vector machines are very powerful, and before
you try neural networks try SVMs with different kernels.</p>
<p>These are the
<a href="http://user.it.uu.se/~justin/Assets/Teaching/IntroML/Slides/lecture5.pdf" target="_blank">slides</a>
that I use.</p>
<h2 id="reading-guide">Reading Guide</h2>
<ul>
<li><a href="http://themlbook.com/" target="_blank">Hundred-Page Machine Learning Book</a> <a href="https://www.dropbox.com/s/qiq2c85cle9ydb6/Chapter3.pdf?dl=0" target="_blank">Chapter
3</a>
section 3.4, <a href="https://www.dropbox.com/s/lrhtt1wkffnm4fe/Chapter1.pdf?dl=0" target="_blank">Chapter
1</a>
sections 1.3  and 1.4 again and <a href="https://www.dropbox.com/s/esprbgjm0wc5afz/Chapter7.pdf?dl=0" target="_blank">Chapter
7</a>
sections 7.1,7.2 and 7.3.</li>
<li>The Wikipedia page on the <a href="https://en.wikipedia.org/wiki/Kernel_method" target="_blank">Kernel
Method</a> is a good
starting point for the kernel trick and a reference on different
Kernels. The whole Wikipedia article on
<a href="https://en.wikipedia.org/wiki/Support-vector_machine" target="_blank">SVMs</a> is also
a good starting point that includes a very good set of references.</li>
</ul>
<h2 id="what-should-i-know-by-the-end-of-this-lecture">What should I know by the end of this lecture?</h2>
<ul>
<li>What are Support Vector Machines?</li>
<li>What is a large margin classifier?</li>
<li>What is the hinge loss function?</li>
<li>What are Kernels? You should know some common kernels including the
polynomial kernel and the Gaussian kernel (or radial bases kernel).</li>
<li>What is the Kernel trick?</li>
<li>How does the learning algorithm work for SVMs?</li>
</ul>

            <footer class="footline">
            </footer>
          </article>

        </div>
      </main>
    </div>
    <script src="/js/clipboard.min.js?1709192834" defer></script>
    <script src="/js/perfect-scrollbar.min.js?1709192834" defer></script>
    <script src="/js/theme.js?1709192834" defer></script>
  </body>
</html>
