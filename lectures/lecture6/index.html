<!doctype html><html lang=en dir=ltr itemscope itemtype=http://schema.org/Article data-r-output-format=html><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.140.2"><meta name=generator content="Relearn 7.3.1"><meta name=description content="Today’s Topics In today’s lecture you will look at various techniques to deal with and understand overfitting. Dealing with overfitting leads nicely to the model selection problem. First and foremost, how do you decide which machine learning algorithm to use. Further, in many machine learning algorithms there are hyper-parameters that are not decided by the training data. Choosing which model to use or values of the models hyper-parameters is a difficult task and can greatly affect the performance of you algorithm. Cross validation is a useful technique from statistics that allows you to partition your data up into many combinations of training, test and validation sets. You can then use cross validation to help you decide which machine learning model to use and what values to set the hyper-parameters."><meta name=author content="Justin Pearson"><meta name=twitter:card content="summary"><meta name=twitter:title content="Lecture 6: Cross Validation and Feature Engineering :: 1DL034"><meta name=twitter:description content="Today’s Topics In today’s lecture you will look at various techniques to deal with and understand overfitting. Dealing with overfitting leads nicely to the model selection problem. First and foremost, how do you decide which machine learning algorithm to use. Further, in many machine learning algorithms there are hyper-parameters that are not decided by the training data. Choosing which model to use or values of the models hyper-parameters is a difficult task and can greatly affect the performance of you algorithm. Cross validation is a useful technique from statistics that allows you to partition your data up into many combinations of training, test and validation sets. You can then use cross validation to help you decide which machine learning model to use and what values to set the hyper-parameters."><meta property="og:url" content="https://intro-ml-1dl034-uu-se.github.io/lectures/lecture6/index.html"><meta property="og:site_name" content="1DL034"><meta property="og:title" content="Lecture 6: Cross Validation and Feature Engineering :: 1DL034"><meta property="og:description" content="Today’s Topics In today’s lecture you will look at various techniques to deal with and understand overfitting. Dealing with overfitting leads nicely to the model selection problem. First and foremost, how do you decide which machine learning algorithm to use. Further, in many machine learning algorithms there are hyper-parameters that are not decided by the training data. Choosing which model to use or values of the models hyper-parameters is a difficult task and can greatly affect the performance of you algorithm. Cross validation is a useful technique from statistics that allows you to partition your data up into many combinations of training, test and validation sets. You can then use cross validation to help you decide which machine learning model to use and what values to set the hyper-parameters."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="Lectures"><meta itemprop=name content="Lecture 6: Cross Validation and Feature Engineering :: 1DL034"><meta itemprop=description content="Today’s Topics In today’s lecture you will look at various techniques to deal with and understand overfitting. Dealing with overfitting leads nicely to the model selection problem. First and foremost, how do you decide which machine learning algorithm to use. Further, in many machine learning algorithms there are hyper-parameters that are not decided by the training data. Choosing which model to use or values of the models hyper-parameters is a difficult task and can greatly affect the performance of you algorithm. Cross validation is a useful technique from statistics that allows you to partition your data up into many combinations of training, test and validation sets. You can then use cross validation to help you decide which machine learning model to use and what values to set the hyper-parameters."><meta itemprop=wordCount content="290"><title>Lecture 6: Cross Validation and Feature Engineering :: 1DL034</title>
<link href=/lectures/lecture6/index.xml rel=alternate type=application/rss+xml title="Lecture 6: Cross Validation and Feature Engineering :: 1DL034"><link href=/lectures/lecture6/index.print.html rel=alternate type=text/html title="Lecture 6: Cross Validation and Feature Engineering :: 1DL034"><link href=/css/fontawesome-all.min.css?1736242352 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/css/fontawesome-all.min.css?1736242352 rel=stylesheet></noscript><link href=/css/auto-complete.css?1736242352 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/css/auto-complete.css?1736242352 rel=stylesheet></noscript><link href=/css/perfect-scrollbar.min.css?1736242352 rel=stylesheet><link href=/css/theme.min.css?1736242352 rel=stylesheet><link href=/css/format-html.min.css?1736242352 rel=stylesheet id=R-format-style><script>window.relearn=window.relearn||{},window.relearn.relBasePath="../..",window.relearn.relBaseUri="../..",window.relearn.absBaseUri="https://intro-ml-1dl034-uu-se.github.io",window.relearn.min=`.min`,window.relearn.disableAnchorCopy=!1,window.relearn.disableAnchorScrolling=!1,window.relearn.themevariants=["blue"],window.relearn.customvariantname="my-custom-variant",window.relearn.changeVariant=function(e){var t=document.documentElement.dataset.rThemeVariant;window.localStorage.setItem(window.relearn.absBaseUri+"/variant",e),document.documentElement.dataset.rThemeVariant=e,t!=e&&document.dispatchEvent(new CustomEvent("themeVariantLoaded",{detail:{variant:e,oldVariant:t}}))},window.relearn.markVariant=function(){var t=window.localStorage.getItem(window.relearn.absBaseUri+"/variant"),e=document.querySelector("#R-select-variant");e&&(e.value=t)},window.relearn.initVariant=function(){var e=window.localStorage.getItem(window.relearn.absBaseUri+"/variant")??"";e==window.relearn.customvariantname||(!e||!window.relearn.themevariants.includes(e))&&(e=window.relearn.themevariants[0],window.localStorage.setItem(window.relearn.absBaseUri+"/variant",e)),document.documentElement.dataset.rThemeVariant=e},window.relearn.initVariant(),window.relearn.markVariant(),window.T_Copy_to_clipboard=`Copy to clipboard`,window.T_Copied_to_clipboard=`Copied to clipboard!`,window.T_Copy_link_to_clipboard=`Copy link to clipboard`,window.T_Link_copied_to_clipboard=`Copied link to clipboard!`,window.T_Reset_view=`Reset view`,window.T_View_reset=`View reset!`,window.T_No_results_found=`No results found for "{0}"`,window.T_N_results_found=`{1} results found for "{0}"`</script></head><body class="mobile-support html" data-url=/lectures/lecture6/index.html><div id=R-body class=default-animation><div id=R-body-overlay></div><nav id=R-topbar><div class=topbar-wrapper><div class=topbar-sidebar-divider></div><div class="topbar-area topbar-area-start" data-area=start><div class="topbar-button topbar-button-sidebar" data-content-empty=disable data-width-s=show data-width-m=hide data-width-l=hide><button class=topbar-control onclick=toggleNav() type=button title="Menu (CTRL+ALT+n)"><i class="fa-fw fas fa-bars"></i></button></div></div><ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype=http://schema.org/BreadcrumbList><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/index.html><span itemprop=name>Introduction to Machine Learning 1DL034</span></a><meta itemprop=position content="1">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/lectures/index.html><span itemprop=name>Lectures</span></a><meta itemprop=position content="2">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><span itemprop=name>Lecture 6</span><meta itemprop=position content="3"></li></ol><div class="topbar-area topbar-area-end" data-area=end><div class="topbar-button topbar-button-print" data-content-empty=disable data-width-s=area-more data-width-m=show data-width-l=show><a class=topbar-control href=/lectures/lecture6/index.print.html title="Print whole chapter (CTRL+ALT+p)"><i class="fa-fw fas fa-print"></i></a></div><div class="topbar-button topbar-button-more" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title=More><i class="fa-fw fas fa-ellipsis-v"></i></button><div class=topbar-content><div class=topbar-content-wrapper><div class="topbar-area topbar-area-more" data-area=more></div></div></div></div></div></div></nav><div id=R-main-overlay></div><main id=R-body-inner class="highlightable lectures" tabindex=-1><div class=flex-block-wrapper><article class=default><header class=headline></header><h1 id=lecture-6-cross-validation-and-feature-engineering>Lecture 6: Cross Validation and Feature Engineering</h1><h2 id=todays-topics>Today&rsquo;s Topics</h2><p>In today&rsquo;s lecture you will look at various techniques to deal with
and understand overfitting. Dealing with overfitting leads nicely to
the model selection problem. First and foremost, how do you decide
which machine learning algorithm to use. Further, in many machine
learning algorithms there are hyper-parameters that are not decided by
the training data. Choosing which model to use or values of the models
hyper-parameters is a difficult task and can greatly affect the
performance of you algorithm. Cross validation is a useful technique
from statistics that allows you to partition your data up into many
combinations of training, test and validation sets. You can then use
cross validation to help you decide which machine learning model to
use and what values to set the hyper-parameters.</p><p>Finally we will cover various techniques for data-normalisation, and
dealing with categorical data. One important thing to remember is that
a little bit of data prepossessing can often improve the performance
of your learning algorithm significantly.</p><h2 id=slides>Slides</h2><p>I used these
<a href=http://user.it.uu.se/~justin/Assets/Teaching/IntroML/Slides/lecture6.pdf rel=external target=_blank>slides</a>
in the lecture.</p><h2 id=reading-guide>Reading Guide</h2><ul><li><p><a href=http://themlbook.com/ rel=external target=_blank>Hundred-Page Machine Learning Book</a> the
whole of <a href="https://www.dropbox.com/s/nije38rerpfa18o/Chapter5.pdf?dl=0" rel=external target=_blank>Chapter 5</a>.</p></li><li><p><a href=https://www.holehouse.org/mlclass/10_Advice_for_applying_machine_learning.html rel=external target=_blank>Notes from Andrew Ng&rsquo;s Lectures</a></p></li><li><p><a href=https://machinelearningmastery.com/k-fold-cross-validation/ rel=external target=_blank>Machine learning mastery on cross
validation</a></p></li><li><p>Last year when I taught the course live, I used these
<a href=http://user.it.uu.se/~justin/Assets/Teaching/IntroML/Slides/lecture_cross.pdf rel=external target=_blank>notes</a>
that you might find useful.</p></li></ul><h2 id=what-should-i-know-by-the-end-of-this-lecture>What should I know by the end of this lecture?</h2><ul><li>What is over fitting? what are some strategies to avoid it?</li><li>What is the bias</li><li>What is the model selection problem?</li><li>What are hyper-parameters?</li><li>Why do you need to split data in training, test and validation sets?</li><li>What is cross validation?</li><li>What is k-fold cross validation?</li><li>What are the different encoding strategies for categorical data?
One-hot encoding, dummy encoding?</li><li>What is data normalisation and when is it necessary?</li></ul><footer class=footline></footer></article></div></main></div><aside id=R-sidebar class=default-animation><div id=R-header-topbar class=default-animation></div><div id=R-header-wrapper class=default-animation><div id=R-header class=default-animation><a id=R-logo class=R-default href=/index.html>1DL034</a></div><script>window.index_js_url="/searchindex.en.js?1736242352"</script><search><form action=/search/index.html method=get><div class="searchbox default-animation"><button class=search-detail type=submit title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
<label class=a11y-only for=R-search-by>Search</label>
<input data-search-input id=R-search-by name=search-by class=search-by type=search placeholder=Search...>
<button class=search-clear type=button data-search-clear title="Clear search"><i class="fas fa-times" title="Clear search"></i></button></div></form></search><script>var contentLangs=["en"]</script><script src=/js/auto-complete.js?1736242352 defer></script><script src=/js/lunr/lunr.min.js?1736242352 defer></script><script src=/js/lunr/lunr.stemmer.support.min.js?1736242352 defer></script><script src=/js/lunr/lunr.multi.min.js?1736242352 defer></script><script src=/js/lunr/lunr.en.min.js?1736242352 defer></script><script src=/js/search.js?1736242352 defer></script></div><div id=R-homelinks class="default-animation homelinks"><ul><li><a class=padding href=/index.html><i class="fa-fw fas fa-home"></i> Home</a></li></ul><hr class=padding></div><div id=R-content-wrapper class=highlightable><div id=R-shortcutmenu-home class=R-sidebarmenu><ul class="enlarge morespace collapsible-menu"><li class=parent data-nav-id=/lectures/index.html><a class=padding href=/lectures/index.html>Lectures</a><ul id=R-subsections-bd2d5f2640929874ad03ea9fdcb748e9 class=collapsible-menu><li data-nav-id=/lectures/lecture1/index.html><a class=padding href=/lectures/lecture1/index.html>Lecture 1</a></li><li data-nav-id=/lectures/lecture2/index.html><a class=padding href=/lectures/lecture2/index.html>Lecture 2</a></li><li class=alwaysopen data-nav-id=/lectures/lecture3/index.html><a class=padding href=/lectures/lecture3/index.html>Lecture 3</a><ul id=R-subsections-169a72b8fc4f8ed04f8294163259b704 class=collapsible-menu></ul></li><li data-nav-id=/lectures/lecture4/index.html><a class=padding href=/lectures/lecture4/index.html>Lecture 4</a></li><li data-nav-id=/lectures/lecture5/index.html><a class=padding href=/lectures/lecture5/index.html>Lecture 5</a></li><li class=active data-nav-id=/lectures/lecture6/index.html><a class=padding href=/lectures/lecture6/index.html>Lecture 6</a></li><li data-nav-id=/lectures/lecture7/index.html><a class=padding href=/lectures/lecture7/index.html>Lecture 7</a></li><li data-nav-id=/lectures/lecture8/index.html><a class=padding href=/lectures/lecture8/index.html>Lecture 8</a></li><li data-nav-id=/lectures/lecture9/index.html><a class=padding href=/lectures/lecture9/index.html>Lecture 9</a></li><li data-nav-id=/lectures/lecture10/index.html><a class=padding href=/lectures/lecture10/index.html>Lecture 10</a></li></ul></li><li data-nav-id=/labs/index.html><a class=padding href=/labs/index.html>Assignments and Project</a></li><li data-nav-id=/resources/index.html><a class=padding href=/resources/index.html>Resources</a><ul id=R-subsections-99e912a437a5f6bb24332b3308c69481 class=collapsible-menu></ul></li></ul></div><div id=R-shortcutmenu-shortcuts class=R-sidebarmenu><div class="nav-title padding">More</div><ul class="space collapsible-menu"><li data-nav-id=https://github.com/JustinKennethPearson/ml-1dl034-public-assignments><a class=padding href=https://github.com/JustinKennethPearson/ml-1dl034-public-assignments target=_blank><i class='fab fa-fw fa-github'></i> GitHub repo</a></li><li data-nav-id=https://user.it.uu.se/~justin/Hugo/><a class=padding href=https://user.it.uu.se/~justin/Hugo/ target=_blank><i class='fas fa-home'></i> Homepage</a></li></ul></div><div class="padding footermargin footerLangSwitch footerVariantSwitch footerVisitedLinks footerFooter showFooter"></div><div id=R-menu-footer><hr class="padding default-animation footerLangSwitch footerVariantSwitch footerVisitedLinks footerFooter showFooter"><div id=R-prefooter class="footerLangSwitch footerVariantSwitch footerVisitedLinks"><ul><li id=R-select-language-container class=footerLangSwitch><div class="padding menu-control"><i class="fa-fw fas fa-language"></i>
<span>&nbsp;</span><div class=control-style><label class=a11y-only for=R-select-language>Language</label>
<select id=R-select-language onchange="location=this.querySelector(this.value).dataset.url"><option id=R-select-language-en value=#R-select-language-en data-url=/lectures/lecture6/index.html lang=en selected></option></select></div><div class=clear></div></div></li><li id=R-select-variant-container class=footerVariantSwitch><div class="padding menu-control"><i class="fa-fw fas fa-paint-brush"></i>
<span>&nbsp;</span><div class=control-style><label class=a11y-only for=R-select-variant>Theme</label>
<select id=R-select-variant onchange=window.relearn.changeVariant(this.value)><option id=R-select-variant-blue value=blue selected>Blue</option></select></div><div class=clear></div></div><script>window.relearn.markVariant()</script></li><li class=footerVisitedLinks><div class="padding menu-control"><i class="fa-fw fas fa-history"></i>
<span>&nbsp;</span><div class=control-style><button onclick=clearHistory()>Clear History</button></div><div class=clear></div></div></li></ul></div><div id=R-footer class="footerFooter showFooter"><p>Built with <a href=https://github.com/McShelby/hugo-theme-relearn title=love><i class="fas fa-heart"></i></a> by <a href=https://gohugo.io/>Hugo</a></p></div></div></div></aside><script src=/js/clipboard.min.js?1736242352 defer></script><script src=/js/perfect-scrollbar.min.js?1736242352 defer></script><script src=/js/theme.js?1736242352 defer></script></body></html>