<!doctype html><html lang=en dir=ltr itemscope itemtype=http://schema.org/Article><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.138.0"><meta name=generator content="Relearn 7.1.1"><meta name=description content="Today’s Topics In this segment you are looking at some unsupervised algorithms, as well as one supervised learning method (K-nearest neighbours) The main unsupervised algorithms are Hierarchical clustering, K-means clustering and DBSCAN. It is important not to get K-nearest neighbours and K-means clustering confused.
The K-means algorithm works by gradient descent. Unlike a lot of the algorithms that we have been looking at, K-means often suffers from the problem of many local minima. In Andrew Ng’s lectures you will meet various ways of dealing with local minima."><meta name=author content="Justin Pearson"><meta name=twitter:card content="summary"><meta name=twitter:title content="Lecture 7: Clustering and Nearest Neighbours :: Introduction to ML 1D034 homepage."><meta name=twitter:description content="Today’s Topics In this segment you are looking at some unsupervised algorithms, as well as one supervised learning method (K-nearest neighbours) The main unsupervised algorithms are Hierarchical clustering, K-means clustering and DBSCAN. It is important not to get K-nearest neighbours and K-means clustering confused.
The K-means algorithm works by gradient descent. Unlike a lot of the algorithms that we have been looking at, K-means often suffers from the problem of many local minima. In Andrew Ng’s lectures you will meet various ways of dealing with local minima."><meta property="og:url" content="https://intro-ml-1dl034-uu-se.github.io/lectures/lecture7/index.html"><meta property="og:site_name" content="Introduction to ML 1D034 homepage."><meta property="og:title" content="Lecture 7: Clustering and Nearest Neighbours :: Introduction to ML 1D034 homepage."><meta property="og:description" content="Today’s Topics In this segment you are looking at some unsupervised algorithms, as well as one supervised learning method (K-nearest neighbours) The main unsupervised algorithms are Hierarchical clustering, K-means clustering and DBSCAN. It is important not to get K-nearest neighbours and K-means clustering confused.
The K-means algorithm works by gradient descent. Unlike a lot of the algorithms that we have been looking at, K-means often suffers from the problem of many local minima. In Andrew Ng’s lectures you will meet various ways of dealing with local minima."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="Lectures"><meta itemprop=name content="Lecture 7: Clustering and Nearest Neighbours :: Introduction to ML 1D034 homepage."><meta itemprop=description content="Today’s Topics In this segment you are looking at some unsupervised algorithms, as well as one supervised learning method (K-nearest neighbours) The main unsupervised algorithms are Hierarchical clustering, K-means clustering and DBSCAN. It is important not to get K-nearest neighbours and K-means clustering confused.
The K-means algorithm works by gradient descent. Unlike a lot of the algorithms that we have been looking at, K-means often suffers from the problem of many local minima. In Andrew Ng’s lectures you will meet various ways of dealing with local minima."><meta itemprop=wordCount content="344"><title>Lecture 7: Clustering and Nearest Neighbours :: Introduction to ML 1D034 homepage.</title>
<link href=/lectures/lecture7/index.xml rel=alternate type=application/rss+xml title="Lecture 7: Clustering and Nearest Neighbours :: Introduction to ML 1D034 homepage."><link href=/lectures/lecture7/index.print.html rel=alternate type=text/html title="Lecture 7: Clustering and Nearest Neighbours :: Introduction to ML 1D034 homepage."><link href=/css/fontawesome-all.min.css?1731513417 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/css/fontawesome-all.min.css?1731513417 rel=stylesheet></noscript><link href=/css/nucleus.css?1731513417 rel=stylesheet><link href=/css/auto-complete.css?1731513417 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/css/auto-complete.css?1731513417 rel=stylesheet></noscript><link href=/css/perfect-scrollbar.min.css?1731513417 rel=stylesheet><link href=/css/fonts.css?1731513417 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/css/fonts.css?1731513417 rel=stylesheet></noscript><link href=/css/theme.css?1731513417 rel=stylesheet><link href=/css/theme-blue.css?1731513417 rel=stylesheet id=R-variant-style><link href=/css/chroma-learn.css?1731513417 rel=stylesheet id=R-variant-chroma-style><link href=/css/print.css?1731513417 rel=stylesheet media=print><script src=/js/variant.js?1731513417></script><script>window.relearn=window.relearn||{},window.relearn.relBasePath="../..",window.relearn.relBaseUri="../..",window.relearn.absBaseUri="https://intro-ml-1dl034-uu-se.github.io",window.relearn.disableAnchorCopy=!1,window.relearn.disableAnchorScrolling=!1,window.variants&&variants.init(["blue"]),window.T_Copy_to_clipboard=`Copy to clipboard`,window.T_Copied_to_clipboard=`Copied to clipboard!`,window.T_Copy_link_to_clipboard=`Copy link to clipboard`,window.T_Link_copied_to_clipboard=`Copied link to clipboard!`,window.T_Reset_view=`Reset view`,window.T_View_reset=`View reset!`,window.T_No_results_found=`No results found for "{0}"`,window.T_N_results_found=`{1} results found for "{0}"`</script></head><body class="mobile-support html" data-url=/lectures/lecture7/index.html><div id=R-body class=default-animation><div id=R-body-overlay></div><nav id=R-topbar><div class=topbar-wrapper><div class=topbar-sidebar-divider></div><div class="topbar-area topbar-area-start" data-area=start><div class="topbar-button topbar-button-sidebar" data-content-empty=disable data-width-s=show data-width-m=hide data-width-l=hide><button class=topbar-control onclick=toggleNav() type=button title="Menu (CTRL+ALT+n)"><i class="fa-fw fas fa-bars"></i></button></div></div><ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype=http://schema.org/BreadcrumbList><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/index.html><span itemprop=name>Introduction to Machine Learning 1DL034</span></a><meta itemprop=position content="1">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/lectures/index.html><span itemprop=name>Lectures</span></a><meta itemprop=position content="2">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><span itemprop=name>Lecture 7</span><meta itemprop=position content="3"></li></ol><div class="topbar-area topbar-area-end" data-area=end><div class="topbar-button topbar-button-print" data-content-empty=disable data-width-s=area-more data-width-m=show data-width-l=show><a class=topbar-control href=/lectures/lecture7/index.print.html title="Print whole chapter (CTRL+ALT+p)"><i class="fa-fw fas fa-print"></i></a></div><div class="topbar-button topbar-button-more" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title=More><i class="fa-fw fas fa-ellipsis-v"></i></button><div class=topbar-content><div class=topbar-content-wrapper><div class="topbar-area topbar-area-more" data-area=more></div></div></div></div></div></div></nav><div id=R-main-overlay></div><main id=R-body-inner class="highlightable lectures" tabindex=-1><div class=flex-block-wrapper><article class=default><header class=headline></header><h1 id=lecture-7-clustering-and-nearest-neighbours>Lecture 7: Clustering and Nearest Neighbours</h1><h2 id=todays-topics>Today&rsquo;s Topics</h2><p>In this segment you are looking at some unsupervised algorithms, as
well as one supervised learning method (K-nearest neighbours) The
main unsupervised algorithms are Hierarchical clustering, K-means
clustering and DBSCAN. It is important not to get K-nearest neighbours
and K-means clustering confused.</p><p>The K-means algorithm works by gradient descent. Unlike a lot of the
algorithms that we have been looking at, K-means often suffers from
the problem of many local minima. In Andrew Ng&rsquo;s lectures you will
meet various ways of dealing with local minima.</p><p>If you have taken <a href=https://ad2-uu-se.github.io/ rel=external target=_blank>Algorithms and Data Structures II</a>(<a href="https://www.uu.se/en/admissions/master/selma/kursplan/?kKod=1DL231" rel=external target=_blank>1DL231</a>)
or AD3
(<a href="https://www.uu.se/en/admissions/master/selma/kursplan/?kKod=1DL481" rel=external target=_blank>1DL481</a>),
then you will have met the concept of <a href=https://ad2-uu-se.github.io/lectures/lectures12-13/index.html rel=external target=_blank>NP-hardness</a>. K-means clustering is NP-hard
(see the reference below). This means that the problem is not easy to
solve. If you could guarantee that there would only be one global
minimum then gradient descent would be an efficient algorithm. This
implies that there will always often be local minima in K-means
clustering.</p><h2 id=slides>Slides</h2><p>I used these
<a href=http://user.it.uu.se/~justin/Assets/Teaching/IntroML/Slides/lecture7.pdf rel=external target=_blank>slides</a>
in the lecture.</p><h2 id=reading-guide>Reading Guide</h2><h3 id=k-means-clustering>K-Means Clustering</h3><ul><li><a href=http://themlbook.com/ rel=external target=_blank>Hundred-Page Machine Learning Book</a> <a href="https://www.dropbox.com/s/qiq2c85cle9ydb6/Chapter3.pdf?dl=0" rel=external target=_blank>Chapter
3</a>
section 3.5 and <a href="https://www.dropbox.com/s/y9a7b0hzmuksqar/Chapter9.pdf?dl=0" rel=external target=_blank>Chapter
9</a> all
of 9.2</li><li>Chapter 6 (6.1 and 6.2) of <a href=https://tinyurl.com/y2obtldw rel=external target=_blank>A First Course in Machine
Learning</a>. The link takes you to the
electronic copy in the library.</li><li>This is only for reference: <a href=https://cseweb.ucsd.edu/~avattani/papers/kmeans_hardness.pdf rel=external target=_blank>NP Hardness of K-means
clustering</a>. You
don&rsquo;t need to understand the proof, although you should be aware of
its implications. No greedy/gradient descent algorithm for K-means
is going to be exact.</li></ul><h3 id=k-nearest-neighbours>K-Nearest Neighbours</h3><ul><li>The <a href=https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm rel=external target=_blank>Wikipedia page on K-Nearest
Neighbours</a>
is a good starting point.</li></ul><h2 id=what-should-i-know-by-the-end-of-this-lecture>What should I know by the end of this lecture?</h2><ul><li>What are some of the applications of clustering?</li><li>What is hierarchical clustering and what algorithms are there?</li><li>How does the K-means algorithm work? What is the cost function?</li><li>What is a local optima and why is it a problem with the K-means
algorithm?</li><li>What are some approaches to choosing the number of clusters in
K-means?</li><li>How does the K-nearest neighbour algorithm work and what are some of
its applications?</li><li>What is DBSCAN and how does it work?</li></ul><footer class=footline></footer></article></div></main></div><aside id=R-sidebar class=default-animation><div id=R-header-topbar class=default-animation></div><div id=R-header-wrapper class=default-animation><div id=R-header class=default-animation><a id=R-logo class=R-default href=/index.html>Introduction to ML 1D034 homepage.</a></div><script>window.index_js_url="/searchindex.en.js?1731513417"</script><search><form action=/search/index.html method=get><div class="searchbox default-animation"><button class=search-detail type=submit title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
<label class=a11y-only for=R-search-by>Search</label>
<input data-search-input id=R-search-by name=search-by class=search-by type=search placeholder=Search...>
<button class=search-clear type=button data-search-clear title="Clear search"><i class="fas fa-times" title="Clear search"></i></button></div></form></search><script>var contentLangs=["en"]</script><script src=/js/auto-complete.js?1731513417 defer></script><script src=/js/lunr/lunr.min.js?1731513417 defer></script><script src=/js/lunr/lunr.stemmer.support.min.js?1731513417 defer></script><script src=/js/lunr/lunr.multi.min.js?1731513417 defer></script><script src=/js/lunr/lunr.en.min.js?1731513417 defer></script><script src=/js/search.js?1731513417 defer></script></div><div id=R-homelinks class="default-animation homelinks"><ul><li><a class=padding href=/index.html><i class="fa-fw fas fa-home"></i> Home</a></li></ul><hr class=padding></div><div id=R-content-wrapper class=highlightable><div id=R-shortcutmenu-home class=R-sidebarmenu><ul class="enlarge morespace collapsible-menu"><li class=parent data-nav-id=/lectures/index.html><a class=padding href=/lectures/index.html>Lectures</a><ul id=R-subsections-bd2d5f2640929874ad03ea9fdcb748e9 class=collapsible-menu><li data-nav-id=/lectures/lecture1/index.html><a class=padding href=/lectures/lecture1/index.html>Lecture 1</a></li><li data-nav-id=/lectures/lecture2/index.html><a class=padding href=/lectures/lecture2/index.html>Lecture 2</a></li><li class=alwaysopen data-nav-id=/lectures/lecture3/index.html><a class=padding href=/lectures/lecture3/index.html>Lecture 3</a><ul id=R-subsections-169a72b8fc4f8ed04f8294163259b704 class=collapsible-menu></ul></li><li data-nav-id=/lectures/lecture4/index.html><a class=padding href=/lectures/lecture4/index.html>Lecture 4</a></li><li data-nav-id=/lectures/lecture5/index.html><a class=padding href=/lectures/lecture5/index.html>Lecture 5</a></li><li data-nav-id=/lectures/lecture6/index.html><a class=padding href=/lectures/lecture6/index.html>Lecture 6</a></li><li class=active data-nav-id=/lectures/lecture7/index.html><a class=padding href=/lectures/lecture7/index.html>Lecture 7</a></li><li data-nav-id=/lectures/lecture8/index.html><a class=padding href=/lectures/lecture8/index.html>Lecture 8</a></li><li data-nav-id=/lectures/lecture9/index.html><a class=padding href=/lectures/lecture9/index.html>Lecture 9</a></li><li data-nav-id=/lectures/lecture10/index.html><a class=padding href=/lectures/lecture10/index.html>Lecture 10</a></li></ul></li><li data-nav-id=/labs/index.html><a class=padding href=/labs/index.html>Assignments and Project</a></li><li data-nav-id=/resources/index.html><a class=padding href=/resources/index.html>Resources</a><ul id=R-subsections-99e912a437a5f6bb24332b3308c69481 class=collapsible-menu></ul></li></ul></div><div id=R-shortcutmenu-shortcuts class=R-sidebarmenu><div class="nav-title padding">More</div><ul class="space collapsible-menu"><li data-nav-id=https://github.com/JustinKennethPearson/ml-1dl034-public-assignments><a class=padding href=https://github.com/JustinKennethPearson/ml-1dl034-public-assignments target=_blank><i class='fab fa-fw fa-github'></i> GitHub repo</a></li><li data-nav-id=https://user.it.uu.se/~justin/Hugo/><a class=padding href=https://user.it.uu.se/~justin/Hugo/ target=_blank><i class='fas fa-home'></i> Homepage</a></li></ul></div><div class="padding footermargin footerLangSwitch footerVariantSwitch footerVisitedLinks footerFooter showFooter"></div><div id=R-menu-footer><hr class="padding default-animation footerLangSwitch footerVariantSwitch footerVisitedLinks footerFooter showFooter"><div id=R-prefooter class="footerLangSwitch footerVariantSwitch footerVisitedLinks"><ul><li id=R-select-language-container class=footerLangSwitch><div class="padding menu-control"><i class="fa-fw fas fa-language"></i>
<span>&nbsp;</span><div class=control-style><label class=a11y-only for=R-select-language>Language</label>
<select id=R-select-language onchange="location=this.querySelector(this.value).dataset.url"><option id=R-select-language-en value=#R-select-language-en data-url=/lectures/lecture7/index.html lang=en selected></option></select></div><div class=clear></div></div></li><li id=R-select-variant-container class=footerVariantSwitch><div class="padding menu-control"><i class="fa-fw fas fa-paint-brush"></i>
<span>&nbsp;</span><div class=control-style><label class=a11y-only for=R-select-variant>Theme</label>
<select id=R-select-variant onchange=window.variants&&variants.changeVariant(this.value)><option id=R-select-variant-blue value=blue selected>Blue</option></select></div><div class=clear></div></div><script>window.variants&&variants.markSelectedVariant()</script></li><li class=footerVisitedLinks><div class="padding menu-control"><i class="fa-fw fas fa-history"></i>
<span>&nbsp;</span><div class=control-style><button onclick=clearHistory()>Clear History</button></div><div class=clear></div></div></li></ul></div><div id=R-footer class="footerFooter showFooter"><p>Built with <a href=https://github.com/McShelby/hugo-theme-relearn title=love><i class="fas fa-heart"></i></a> by <a href=https://gohugo.io/>Hugo</a></p></div></div></div></aside><script src=/js/clipboard.min.js?1731513417 defer></script><script src=/js/perfect-scrollbar.min.js?1731513417 defer></script><script src=/js/theme.js?1731513417 defer></script></body></html>