<!doctype html><html lang=en dir=ltr itemscope itemtype=http://schema.org/Article data-r-output-format=html><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.145.0"><meta name=generator content="Relearn 7.3.1"><meta name=description content="Today’s Topics As we have seen before it is often a good idea to do some pre-processing of your input data. Sometimes there are linear relationships hidden in the data, and if you do not remove or discover them then your machine learning algorithm will be trying to learn these linear relationships. In linear algebra, principle component analysis (PCA) is a well established method of reducing the dimension of a data set. It uses eigenvalues and eigenvectors to uncover hidden linear relationships in your data-set. For this course you do not need to know how to actually compute eigenvalues and eigenvectors by hand, but you should understand the definition and what is going on."><meta name=author content="Justin Pearson"><meta name=twitter:card content="summary"><meta name=twitter:title content="Lecture 9: Principle Component Analysis and Preprocessing :: 1DL034"><meta name=twitter:description content="Today’s Topics As we have seen before it is often a good idea to do some pre-processing of your input data. Sometimes there are linear relationships hidden in the data, and if you do not remove or discover them then your machine learning algorithm will be trying to learn these linear relationships. In linear algebra, principle component analysis (PCA) is a well established method of reducing the dimension of a data set. It uses eigenvalues and eigenvectors to uncover hidden linear relationships in your data-set. For this course you do not need to know how to actually compute eigenvalues and eigenvectors by hand, but you should understand the definition and what is going on."><meta property="og:url" content="https://intro-ml-1dl034-uu-se.github.io/lectures/lecture9/index.html"><meta property="og:site_name" content="1DL034"><meta property="og:title" content="Lecture 9: Principle Component Analysis and Preprocessing :: 1DL034"><meta property="og:description" content="Today’s Topics As we have seen before it is often a good idea to do some pre-processing of your input data. Sometimes there are linear relationships hidden in the data, and if you do not remove or discover them then your machine learning algorithm will be trying to learn these linear relationships. In linear algebra, principle component analysis (PCA) is a well established method of reducing the dimension of a data set. It uses eigenvalues and eigenvectors to uncover hidden linear relationships in your data-set. For this course you do not need to know how to actually compute eigenvalues and eigenvectors by hand, but you should understand the definition and what is going on."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="Lectures"><meta itemprop=name content="Lecture 9: Principle Component Analysis and Preprocessing :: 1DL034"><meta itemprop=description content="Today’s Topics As we have seen before it is often a good idea to do some pre-processing of your input data. Sometimes there are linear relationships hidden in the data, and if you do not remove or discover them then your machine learning algorithm will be trying to learn these linear relationships. In linear algebra, principle component analysis (PCA) is a well established method of reducing the dimension of a data set. It uses eigenvalues and eigenvectors to uncover hidden linear relationships in your data-set. For this course you do not need to know how to actually compute eigenvalues and eigenvectors by hand, but you should understand the definition and what is going on."><meta itemprop=wordCount content="265"><title>Lecture 9: Principle Component Analysis and Preprocessing :: 1DL034</title>
<link href=/lectures/lecture9/index.xml rel=alternate type=application/rss+xml title="Lecture 9: Principle Component Analysis and Preprocessing :: 1DL034"><link href=/lectures/lecture9/index.print.html rel=alternate type=text/html title="Lecture 9: Principle Component Analysis and Preprocessing :: 1DL034"><link href=/css/fontawesome-all.min.css?1740928677 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/css/fontawesome-all.min.css?1740928677 rel=stylesheet></noscript><link href=/css/auto-complete.css?1740928677 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/css/auto-complete.css?1740928677 rel=stylesheet></noscript><link href=/css/perfect-scrollbar.min.css?1740928677 rel=stylesheet><link href=/css/theme.min.css?1740928677 rel=stylesheet><link href=/css/format-html.min.css?1740928677 rel=stylesheet id=R-format-style><script>window.relearn=window.relearn||{},window.relearn.relBasePath="../..",window.relearn.relBaseUri="../..",window.relearn.absBaseUri="https://intro-ml-1dl034-uu-se.github.io",window.relearn.min=`.min`,window.relearn.disableAnchorCopy=!1,window.relearn.disableAnchorScrolling=!1,window.relearn.themevariants=["blue"],window.relearn.customvariantname="my-custom-variant",window.relearn.changeVariant=function(e){var t=document.documentElement.dataset.rThemeVariant;window.localStorage.setItem(window.relearn.absBaseUri+"/variant",e),document.documentElement.dataset.rThemeVariant=e,t!=e&&document.dispatchEvent(new CustomEvent("themeVariantLoaded",{detail:{variant:e,oldVariant:t}}))},window.relearn.markVariant=function(){var t=window.localStorage.getItem(window.relearn.absBaseUri+"/variant"),e=document.querySelector("#R-select-variant");e&&(e.value=t)},window.relearn.initVariant=function(){var e=window.localStorage.getItem(window.relearn.absBaseUri+"/variant")??"";e==window.relearn.customvariantname||(!e||!window.relearn.themevariants.includes(e))&&(e=window.relearn.themevariants[0],window.localStorage.setItem(window.relearn.absBaseUri+"/variant",e)),document.documentElement.dataset.rThemeVariant=e},window.relearn.initVariant(),window.relearn.markVariant(),window.T_Copy_to_clipboard=`Copy to clipboard`,window.T_Copied_to_clipboard=`Copied to clipboard!`,window.T_Copy_link_to_clipboard=`Copy link to clipboard`,window.T_Link_copied_to_clipboard=`Copied link to clipboard!`,window.T_Reset_view=`Reset view`,window.T_View_reset=`View reset!`,window.T_No_results_found=`No results found for "{0}"`,window.T_N_results_found=`{1} results found for "{0}"`</script></head><body class="mobile-support html" data-url=/lectures/lecture9/index.html><div id=R-body class=default-animation><div id=R-body-overlay></div><nav id=R-topbar><div class=topbar-wrapper><div class=topbar-sidebar-divider></div><div class="topbar-area topbar-area-start" data-area=start><div class="topbar-button topbar-button-sidebar" data-content-empty=disable data-width-s=show data-width-m=hide data-width-l=hide><button class=topbar-control onclick=toggleNav() type=button title="Menu (CTRL+ALT+n)"><i class="fa-fw fas fa-bars"></i></button></div></div><ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype=http://schema.org/BreadcrumbList><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/index.html><span itemprop=name>Introduction to Machine Learning 1DL034</span></a><meta itemprop=position content="1">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/lectures/index.html><span itemprop=name>Lectures</span></a><meta itemprop=position content="2">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><span itemprop=name>Lecture 9</span><meta itemprop=position content="3"></li></ol><div class="topbar-area topbar-area-end" data-area=end><div class="topbar-button topbar-button-print" data-content-empty=disable data-width-s=area-more data-width-m=show data-width-l=show><a class=topbar-control href=/lectures/lecture9/index.print.html title="Print whole chapter (CTRL+ALT+p)"><i class="fa-fw fas fa-print"></i></a></div><div class="topbar-button topbar-button-more" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title=More><i class="fa-fw fas fa-ellipsis-v"></i></button><div class=topbar-content><div class=topbar-content-wrapper><div class="topbar-area topbar-area-more" data-area=more></div></div></div></div></div></div></nav><div id=R-main-overlay></div><main id=R-body-inner class="highlightable lectures" tabindex=-1><div class=flex-block-wrapper><article class=default><header class=headline></header><h1 id=lecture-9-principle-component-analysis-and-preprocessing>Lecture 9: Principle Component Analysis and Preprocessing</h1><h2 id=todays-topics>Today&rsquo;s Topics</h2><p>As we have seen before it is often a good idea to do some
pre-processing of your input data. Sometimes there are linear
relationships hidden in the data, and if you do not remove or discover
them then your machine learning algorithm will be trying to learn
these linear relationships. In linear algebra, principle component
analysis (PCA) is a well established method of reducing the dimension
of a data set. It uses eigenvalues and eigenvectors to uncover hidden
linear relationships in your data-set. For this course you do not need
to know how to actually compute eigenvalues and eigenvectors by hand,
but you should understand the definition and what is going on.</p><p>An interesting application of PCA are
<a href=https://en.wikipedia.org/wiki/Eigenface rel=external target=_blank>Eigenfaces</a>.</p><h2 id=slides>Slides</h2><p>I use <a href=https://user.it.uu.se/~justin/Assets/Teaching/IntroML/Slides/lecture9.pdf rel=external target=_blank>these
slide</a>. In
previous years, I have done the lecture on the blackboard, and these
are some
<a href=https://user.it.uu.se/~justin/Assets/Teaching/IntroML/Slides/lecture9_handwritten.pdf rel=external target=_blank>notes</a>
that I used. They contain some extra derivations.</p><h2 id=reading-guide>Reading Guide</h2><ul><li><a href=http://themlbook.com/ rel=external target=_blank>Hundred-Page Machine Learning Book</a>
<a href="https://www.dropbox.com/s/y9a7b0hzmuksqar/Chapter9.pdf?dl=0" rel=external target=_blank>Chapter 9 section 9.3</a></li><li>Chapter 8 of <a href=https://www.cambridge.org/highereducation/books/a-hands-on-introduction-to-machine-learning/3E57313A963BF7AF5C6330EB88ADAB2E#overview rel=external target=_blank>A Hands-On Introduction to Machine
Learning</a>.</li><li><a href=https://uub.primo.exlibrisgroup.com/permalink/46LIBRIS_UUB/d23b4h/alma991018444332907596 rel=external target=_blank>A First Course in Machine
Learning</a> 7.1,7.2 has a good
derivation of PCA from the point of view of minimising the
variance in the data.</li><li><a href=https://medium.com/apprentice-journal/pca-application-in-machine-learning-4827c07a61db rel=external target=_blank>PCA in Machine
Learning</a><ul><li><a href=https://sebastianraschka.com/Articles/2015_pca_in_3_steps.html rel=external target=_blank>Principal Component
Analysis</a></li><li><a href=https://towardsdatascience.com/pca-eigenvectors-and-eigenvalues-1f968bc6777a rel=external target=_blank>Towards Data Science on PCA</a></li></ul></li></ul><h2 id=what-should-i-know-by-the-end-of-this-lecture>What should I know by the end of this lecture?</h2><ul><li>What is principle competent analysis (PCA)?</li><li>What is the co-variance matrix and what do the entries mean?</li><li>What do the eigenvalues of the co-variance matrix tell you about the
data?</li><li>How do you choose the number of dimensions in PCA?</li><li>What are some applications of PCA in machine learning?</li></ul><footer class=footline></footer></article></div></main></div><aside id=R-sidebar class=default-animation><div id=R-header-topbar class=default-animation></div><div id=R-header-wrapper class=default-animation><div id=R-header class=default-animation><a id=R-logo class=R-default href=/index.html>1DL034</a></div><script>window.index_js_url="/searchindex.en.js?1740928677"</script><search><form action=/search/index.html method=get><div class="searchbox default-animation"><button class=search-detail type=submit title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
<label class=a11y-only for=R-search-by>Search</label>
<input data-search-input id=R-search-by name=search-by class=search-by type=search placeholder=Search...>
<button class=search-clear type=button data-search-clear title="Clear search"><i class="fas fa-times" title="Clear search"></i></button></div></form></search><script>var contentLangs=["en"]</script><script src=/js/auto-complete.js?1740928677 defer></script><script src=/js/lunr/lunr.min.js?1740928677 defer></script><script src=/js/lunr/lunr.stemmer.support.min.js?1740928677 defer></script><script src=/js/lunr/lunr.multi.min.js?1740928677 defer></script><script src=/js/lunr/lunr.en.min.js?1740928677 defer></script><script src=/js/search.js?1740928677 defer></script></div><div id=R-homelinks class="default-animation homelinks"><ul><li><a class=padding href=/index.html><i class="fa-fw fas fa-home"></i> Home</a></li></ul><hr class=padding></div><div id=R-content-wrapper class=highlightable><div id=R-shortcutmenu-home class=R-sidebarmenu><ul class="enlarge morespace collapsible-menu"><li class=parent data-nav-id=/lectures/index.html><a class=padding href=/lectures/index.html>Lectures</a><ul id=R-subsections-bd2d5f2640929874ad03ea9fdcb748e9 class=collapsible-menu><li data-nav-id=/lectures/lecture1/index.html><a class=padding href=/lectures/lecture1/index.html>Lecture 1</a></li><li data-nav-id=/lectures/lecture2/index.html><a class=padding href=/lectures/lecture2/index.html>Lecture 2</a></li><li class=alwaysopen data-nav-id=/lectures/lecture3/index.html><a class=padding href=/lectures/lecture3/index.html>Lecture 3</a><ul id=R-subsections-169a72b8fc4f8ed04f8294163259b704 class=collapsible-menu></ul></li><li data-nav-id=/lectures/lecture4/index.html><a class=padding href=/lectures/lecture4/index.html>Lecture 4</a></li><li data-nav-id=/lectures/lecture5/index.html><a class=padding href=/lectures/lecture5/index.html>Lecture 5</a></li><li data-nav-id=/lectures/lecture6/index.html><a class=padding href=/lectures/lecture6/index.html>Lecture 6</a></li><li data-nav-id=/lectures/lecture7/index.html><a class=padding href=/lectures/lecture7/index.html>Lecture 7</a></li><li data-nav-id=/lectures/lecture8/index.html><a class=padding href=/lectures/lecture8/index.html>Lecture 8</a></li><li class=active data-nav-id=/lectures/lecture9/index.html><a class=padding href=/lectures/lecture9/index.html>Lecture 9</a></li><li data-nav-id=/lectures/lecture10/index.html><a class=padding href=/lectures/lecture10/index.html>Lecture 10</a></li><li data-nav-id=/lectures/lecture11/index.html><a class=padding href=/lectures/lecture11/index.html>Lecture 11</a></li></ul></li><li data-nav-id=/labs/index.html><a class=padding href=/labs/index.html>Assignments and Project</a></li><li data-nav-id=/resources/index.html><a class=padding href=/resources/index.html>Resources</a><ul id=R-subsections-99e912a437a5f6bb24332b3308c69481 class=collapsible-menu></ul></li></ul></div><div id=R-shortcutmenu-shortcuts class=R-sidebarmenu><div class="nav-title padding">More</div><ul class="space collapsible-menu"><li data-nav-id=https://github.com/JustinKennethPearson/ml-1dl034-public-assignments><a class=padding href=https://github.com/JustinKennethPearson/ml-1dl034-public-assignments target=_blank><i class='fab fa-fw fa-github'></i> GitHub repo</a></li><li data-nav-id=https://user.it.uu.se/~justin/Hugo/><a class=padding href=https://user.it.uu.se/~justin/Hugo/ target=_blank><i class='fas fa-home'></i> Homepage</a></li></ul></div><div class="padding footermargin footerLangSwitch footerVariantSwitch footerVisitedLinks footerFooter showFooter"></div><div id=R-menu-footer><hr class="padding default-animation footerLangSwitch footerVariantSwitch footerVisitedLinks footerFooter showFooter"><div id=R-prefooter class="footerLangSwitch footerVariantSwitch footerVisitedLinks"><ul><li id=R-select-language-container class=footerLangSwitch><div class="padding menu-control"><i class="fa-fw fas fa-language"></i>
<span>&nbsp;</span><div class=control-style><label class=a11y-only for=R-select-language>Language</label>
<select id=R-select-language onchange="location=this.querySelector(this.value).dataset.url"><option id=R-select-language-en value=#R-select-language-en data-url=/lectures/lecture9/index.html lang=en selected></option></select></div><div class=clear></div></div></li><li id=R-select-variant-container class=footerVariantSwitch><div class="padding menu-control"><i class="fa-fw fas fa-paint-brush"></i>
<span>&nbsp;</span><div class=control-style><label class=a11y-only for=R-select-variant>Theme</label>
<select id=R-select-variant onchange=window.relearn.changeVariant(this.value)><option id=R-select-variant-blue value=blue selected>Blue</option></select></div><div class=clear></div></div><script>window.relearn.markVariant()</script></li><li class=footerVisitedLinks><div class="padding menu-control"><i class="fa-fw fas fa-history"></i>
<span>&nbsp;</span><div class=control-style><button onclick=clearHistory()>Clear History</button></div><div class=clear></div></div></li></ul></div><div id=R-footer class="footerFooter showFooter"><p>Built with <a href=https://github.com/McShelby/hugo-theme-relearn title=love><i class="fas fa-heart"></i></a> by <a href=https://gohugo.io/>Hugo</a></p></div></div></div></aside><script src=/js/clipboard.min.js?1740928677 defer></script><script src=/js/perfect-scrollbar.min.js?1740928677 defer></script><script src=/js/theme.js?1740928677 defer></script></body></html>