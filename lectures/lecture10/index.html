<!doctype html><html lang=en-uk dir=ltr itemscope itemtype=http://schema.org/Article data-r-output-format=html><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.154.5"><meta name=generator content="Relearn 8.3.0+6dafca9f9e6c9639c4a2b886e097505d5ee31955"><meta name=description content="Slides Link for the slides.
Today’s Topics: Ensemble Learning Ensemble learning is a simple idea. Instead of training one model, we train multiple models and combine the results. A popular ensemble learning algorithm is random forests that combines many decision trees that are trained on random subsets of the features. To build a classifier a majority vote is taken. There are various techniques to improve the system including boosting, bagging and gradient boosting. As you will see below these are not limited to random forests, but to other combinations of learning algorithms. There is a lot extensions and refinements of ensemble methods including AdaBoost. We will only cover gradient boosting and not go too much into the mathematics behind ensemble learning (that is reserved for a more advanced course). The aim of this lecture is to give you access to another powerful machine learning technique."><meta name=author content="Justin Pearson"><meta name=twitter:card content="summary"><meta name=twitter:title content="Lecture 10: Ensemble Learning :: 1DL034"><meta name=twitter:description content="Slides Link for the slides.
Today’s Topics: Ensemble Learning Ensemble learning is a simple idea. Instead of training one model, we train multiple models and combine the results. A popular ensemble learning algorithm is random forests that combines many decision trees that are trained on random subsets of the features. To build a classifier a majority vote is taken. There are various techniques to improve the system including boosting, bagging and gradient boosting. As you will see below these are not limited to random forests, but to other combinations of learning algorithms. There is a lot extensions and refinements of ensemble methods including AdaBoost. We will only cover gradient boosting and not go too much into the mathematics behind ensemble learning (that is reserved for a more advanced course). The aim of this lecture is to give you access to another powerful machine learning technique."><meta property="og:url" content="https://intro-ml-1dl034-uu-se.github.io/lectures/lecture10/index.html"><meta property="og:site_name" content="1DL034"><meta property="og:title" content="Lecture 10: Ensemble Learning :: 1DL034"><meta property="og:description" content="Slides Link for the slides.
Today’s Topics: Ensemble Learning Ensemble learning is a simple idea. Instead of training one model, we train multiple models and combine the results. A popular ensemble learning algorithm is random forests that combines many decision trees that are trained on random subsets of the features. To build a classifier a majority vote is taken. There are various techniques to improve the system including boosting, bagging and gradient boosting. As you will see below these are not limited to random forests, but to other combinations of learning algorithms. There is a lot extensions and refinements of ensemble methods including AdaBoost. We will only cover gradient boosting and not go too much into the mathematics behind ensemble learning (that is reserved for a more advanced course). The aim of this lecture is to give you access to another powerful machine learning technique."><meta property="og:locale" content="en_uk"><meta property="og:type" content="article"><meta property="article:section" content="Lectures"><meta itemprop=name content="Lecture 10: Ensemble Learning :: 1DL034"><meta itemprop=description content="Slides Link for the slides.
Today’s Topics: Ensemble Learning Ensemble learning is a simple idea. Instead of training one model, we train multiple models and combine the results. A popular ensemble learning algorithm is random forests that combines many decision trees that are trained on random subsets of the features. To build a classifier a majority vote is taken. There are various techniques to improve the system including boosting, bagging and gradient boosting. As you will see below these are not limited to random forests, but to other combinations of learning algorithms. There is a lot extensions and refinements of ensemble methods including AdaBoost. We will only cover gradient boosting and not go too much into the mathematics behind ensemble learning (that is reserved for a more advanced course). The aim of this lecture is to give you access to another powerful machine learning technique."><meta itemprop=wordCount content="471"><title>Lecture 10: Ensemble Learning :: 1DL034</title><link href=/lectures/lecture10/index.xml rel=alternate type=application/rss+xml title="Lecture 10: Ensemble Learning :: 1DL034"><link href=/lectures/lecture10/index.print.html rel=alternate type=text/html title="Lecture 10: Ensemble Learning :: 1DL034"><link href=/css/auto-complete/auto-complete.min.css?1768643228 rel=stylesheet><script src=/js/auto-complete/auto-complete.min.js?1768643228 defer></script><script src=/js/search-lunr.min.js?1768643228 defer></script><script src=/js/search.min.js?1768643228 defer></script><script>window.relearn=window.relearn||{},window.relearn.index_js_url="/searchindex.en.js?1768643228"</script><script src=/js/lunr/lunr.min.js?1768643228 defer></script><script src=/js/lunr/lunr.stemmer.support.min.js?1768643228 defer></script><script src=/js/lunr/lunr.multi.min.js?1768643228 defer></script><script src=/js/lunr/lunr.en.min.js?1768643228 defer></script><script>window.relearn=window.relearn||{},window.relearn.contentLangs=["en"]</script><link href=/fonts/fontawesome/css/fontawesome-all.min.css?1768643228 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/fonts/fontawesome/css/fontawesome-all.min.css?1768643228 rel=stylesheet></noscript><link href=/css/perfect-scrollbar/perfect-scrollbar.min.css?1768643228 rel=stylesheet><link href=/css/theme.min.css?1768643228 rel=stylesheet><link href=/css/format-html.min.css?1768643228 rel=stylesheet id=R-format-style><script>window.relearn=window.relearn||{},window.relearn.min=`.min`,window.relearn.path="/lectures/lecture10/index.html",window.relearn.relBasePath="../..",window.relearn.relBaseUri="../..",window.relearn.absBaseUri="https://intro-ml-1dl034-uu-se.github.io",window.relearn.disableInlineCopyToClipboard=!1,window.relearn.enableBlockCodeWrap=!0,window.relearn.getItem=(e,t)=>e.getItem(t),window.relearn.setItem=(e,t,n)=>e.setItem(t,n),window.relearn.removeItem=(e,t)=>e.removeItem(t),window.T_Copy_to_clipboard=`Copy text to clipboard`,window.T_Copied_to_clipboard=`Text copied to clipboard!`,window.T_Link_copied_to_clipboard=`Link copied to clipboard!`,window.T_Reset_view=`Reset view`,window.T_View_reset=`View reset!`,window.T_No_results_found=`No results found for "{0}"`,window.T_N_results_found=`{1} results found for "{0}"`,window.T_Browser_unsupported_feature=`This browser doesn't support this feature`,window.relearn.themevariants=["blue"],window.relearn.customvariantprefix="my-custom-",window.relearn.changeVariant=function(e){var t=document.documentElement.dataset.rThemeVariant;window.relearn.setItem(window.localStorage,window.relearn.absBaseUri+"/variant",e),document.documentElement.dataset.rThemeVariant=e,t!=e&&(document.dispatchEvent(new CustomEvent("themeVariantLoaded",{detail:{variant:e,oldVariant:t}})),window.relearn.markVariant())},window.relearn.markVariant=function(){var e=window.relearn.getItem(window.localStorage,window.relearn.absBaseUri+"/variant");document.querySelectorAll(".R-variantswitcher select").forEach(t=>{t.value=e})},window.relearn.initVariant=function(){var e=window.relearn.getItem(window.localStorage,window.relearn.absBaseUri+"/variant")??"";(!e||!e.startsWith(window.relearn.customvariantprefix)&&!window.relearn.themevariants.includes(e)||e.startsWith(window.relearn.customvariantprefix)&&!window.relearn.getItem(window.localStorage,window.relearn.absBaseUri+"/variantstylesheet-"+e))&&(e=window.relearn.themevariants[0],window.relearn.setItem(window.localStorage,window.relearn.absBaseUri+"/variant",e)),document.documentElement.dataset.rThemeVariant=e},window.relearn.initVariant(),window.relearn.markVariant()</script></head><body class="mobile-support html" data-url=/lectures/lecture10/index.html><div id=R-body class=default-animation><div id=R-body-overlay></div><nav id=R-topbar class=default-animation><div class="topbar-wrapper default-animation"><div class="topbar-sidebar-divider default-animation"></div><div class="topbar-area topbar-area-start" data-area=start><div class="topbar-button topbar-button-sidebar default-animation" data-content-empty=disable data-width-s=show data-width-m=hide data-width-l=hide><span class="btn cstyle button link noborder notitle interactive"><button onclick=toggleNav() type=button title="Menu (CTRL+ALT+n)"><i class="fa-fw fas fa-bars"></i></button></span></div></div><ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype=http://schema.org/BreadcrumbList><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/index.html><span itemprop=name>Introduction to Machine Learning 1DL034</span></a><meta itemprop=position content="1">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/lectures/index.html><span itemprop=name>Lectures</span></a><meta itemprop=position content="2">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><span itemprop=name>Lecture 10</span><meta itemprop=position content="3"></li></ol><div class="topbar-area topbar-area-end" data-area=end><div class="topbar-button topbar-button-print default-animation" data-content-empty=disable data-width-s=area-more data-width-m=show data-width-l=show><span class="btn cstyle button link noborder notitle interactive"><a href=/lectures/lecture10/index.print.html title="Print whole chapter (CTRL+ALT+p)"><i class="fa-fw fas fa-print"></i></a></span></div><div class="topbar-button topbar-button-more default-animation" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><span class="btn cstyle button link noborder notitle interactive"><button onclick=toggleTopbarFlyout(this) type=button title=More><i class="fa-fw fas fa-ellipsis-v"></i></button></span><div class=topbar-content><div class=topbar-content-wrapper><div class="topbar-area topbar-area-more" data-area=more></div></div></div></div></div></div></nav><div id=R-main-overlay></div><main id=R-body-inner class="highlightable lectures" tabindex=-1><div class=flex-block-wrapper><article class=default><header class=headline></header><h1 id=lecture-10-ensemble-learning>Lecture 10: Ensemble Learning</h1><h2 id=slides>Slides<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>Link for the
<a href=https://user.it.uu.se/~justin/Assets/Teaching/IntroML/Slides/lecture10.pdf rel=external>slides.</a></p><h2 id=todays-topics-ensemble-learning>Today&rsquo;s Topics: Ensemble Learning<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><p>Ensemble learning is a simple idea. Instead of training one model, we
train multiple models and combine the results.
A popular ensemble learning
algorithm is random forests that combines many decision trees that are
trained on random subsets of the features. To build a classifier a
majority vote is taken. There are various techniques to improve the
system including boosting, bagging and gradient boosting. As you will
see below these are not limited to random forests, but to other
combinations of learning algorithms. There is a lot extensions and
refinements of ensemble methods including AdaBoost. We will only
cover gradient boosting and not go too much into the mathematics
behind ensemble learning (that is reserved for a more advanced
course). The aim of this lecture is to give you access to another
powerful machine learning technique.</p><p>One thing that we did not cover in <a href=/lectures/lecture8/index.html>Lecture 8</a> was using decision trees for
regression. Although the idea is not that complicated you should spend
some time understand how Regression trees can be used for
regression. Although you will not be examined on other algorithms for
constructing decisions trees (we covered ID3 in <a href=/lectures/lecture8/index.html>Lecture 8</a> ) you should be aware that
there are other algorithms.</p><p>Constructing the perfect decision tree is
a computationally hard problem (in fact it is NP-complete). For
machine learning we want fast and efficient algorithms for learning,
and most decision tree algorithms in the literature are
approximations.</p><h2 id=reading-guide>Reading Guide<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><ul><li><p><a href=http://themlbook.com/ rel=external>Hundred-Page Machine Learning Book</a> <a href="https://www.dropbox.com/s/qiq2c85cle9ydb6/Chapter3.pdf?dl=0" rel=external>Section
3.3</a> is
a good start on decision trees for regression. Again the book does
not really go into much detail on the algorithms, and it only a
starting point. The wikipedia page on
<a href=https://en.wikipedia.org/wiki/Decision_tree_learning rel=external>Decision tree
learning</a> is a
good starting point and has many useful references to different
learning algorithms.</p></li><li><p><a href=http://themlbook.com/ rel=external>Hundred-Page Machine Learning Book</a>
<a href="https://www.dropbox.com/s/esprbgjm0wc5afz/Chapter7.pdf?dl=0" rel=external>Chapter
7.5</a> is
a good start on ensemble methods but does not go into much
detail. As always with the book, if you do not understand the
explanation then start looking at the references.</p></li><li><p>Section 5.4 of <a href=https://www.cambridge.org/highereducation/books/a-hands-on-introduction-to-machine-learning/3E57313A963BF7AF5C6330EB88ADAB2E#overview rel=external>A Hands-On Introduction to Machine
Learning</a>
cover random forests.</p></li><li><p>Chapter 8 of <a href=https://www.bonaccorso.eu/books/ rel=external>Machine Learning Algorithms</a>
(Bonaccorso, Giuseppe) <a href=http://tinyurl.com/qsse4vb rel=external>online university library
link</a> contains a very good overview of
decision trees and random forests. There are also lots of
scikit-learn code fragments that you can use in your own projects.</p></li><li><p><a href=https://www.kaggle.com/prashant111/bagging-vs-boosting rel=external>A good Kaggle notebook on Bagging and
Boosting</a></p></li><li><p>To explore more than is covered in the book on gradient boosting you
can start at the <a href=https://en.wikipedia.org/wiki/Gradient_boosting rel=external>Wikipedia
page</a> and follow
the references.</p></li><li><p>For your project you should explore scikit-learn
<a href=https://scikit-learn.org/stable/modules/ensemble.html rel=external>API</a> on
ensemble methods.</p></li></ul><h2 id=what-should-i-know-by-the-end-of-this-lecture>What should I know by the end of this lecture?<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><ul><li>How do I use decision trees for regression?</li><li>What is ensemble learning?</li><li>How do random forest work?</li><li>What is boosting and bagging?</li><li>What is gradient boosting?</li></ul><footer class=footline></footer></article></div></main></div><aside id=R-sidebar class=default-animation><div id=R-header-topbar class=default-animation></div><div id=R-header-wrapper class=default-animation><a id=R-logo class="R-default direction-row" href=/index.html><span class="logo-title default-animation">1DL034</span>
</a><search><form action=/search/index.html method=get><div class="searchbox default-animation"><button class=search-detail type=submit title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
<label class=a11y-only for=R-search-by>Search</label>
<input data-search-input id=R-search-by name=search-by class=search-by type=search placeholder=Search...>
<button class=search-clear type=button data-search-clear title="Clear search"><i class="fas fa-times" title="Clear search"></i></button></div></form></search></div><div id=R-homelinks class="default-animation homelinks"><div class="R-menu-divider default-animation"><hr class="padding default-animation"></div><div class="R-sidebarmenu R-shortcutmenu-homelinks default-animation"><ul class="space collapsible-menu"><li data-nav-url=/index.html><a class=padding href=/index.html><i class="fa-fw fas fa-home"></i> Home</a></li></ul></div><div class="R-menu-divider default-animation"><hr class="padding default-animation"></div><div class="R-sidebarmenu R-shortcutmenu-headercontrols default-animation"><ul></ul></div><div class="R-menu-divider default-animation"><hr class="padding default-animation"></div></div><div id=R-content-wrapper class=highlightable><div class="R-sidebarmenu R-shortcutmenu-main default-animation"><ul class="enlarge morespace collapsible-menu"><li class=parent data-nav-url=/lectures/index.html><a class="padding default-animation" href=/lectures/index.html>Lectures</a><ul id=R-subsections-bd2d5f2640929874ad03ea9fdcb748e9 class=collapsible-menu><li data-nav-url=/lectures/lecture1/index.html><a class=padding href=/lectures/lecture1/index.html>Lecture 1</a></li><li data-nav-url=/lectures/lecture2/index.html><a class=padding href=/lectures/lecture2/index.html>Lecture 2</a></li><li class=alwaysopen data-nav-url=/lectures/lecture3/index.html><a class="padding default-animation" href=/lectures/lecture3/index.html>Lecture 3</a><ul id=R-subsections-169a72b8fc4f8ed04f8294163259b704 class=collapsible-menu></ul></li><li data-nav-url=/lectures/lecture4/index.html><a class=padding href=/lectures/lecture4/index.html>Lecture 4</a></li><li data-nav-url=/lectures/lecture5/index.html><a class=padding href=/lectures/lecture5/index.html>Lecture 5</a></li><li data-nav-url=/lectures/lecture6/index.html><a class=padding href=/lectures/lecture6/index.html>Lecture 6</a></li><li data-nav-url=/lectures/lecture7/index.html><a class=padding href=/lectures/lecture7/index.html>Lecture 7</a></li><li data-nav-url=/lectures/lecture8/index.html><a class=padding href=/lectures/lecture8/index.html>Lecture 8</a></li><li data-nav-url=/lectures/lecture9/index.html><a class=padding href=/lectures/lecture9/index.html>Lecture 9</a></li><li class=active data-nav-url=/lectures/lecture10/index.html><a class=padding href=/lectures/lecture10/index.html>Lecture 10</a></li><li data-nav-url=/lectures/lecture11/index.html><a class=padding href=/lectures/lecture11/index.html>Lecture 11</a></li></ul></li><li data-nav-url=/labs/index.html><a class=padding href=/labs/index.html>Assignments and Project</a></li><li data-nav-url=/resources/index.html><a class="padding default-animation" href=/resources/index.html>Resources</a><ul id=R-subsections-99e912a437a5f6bb24332b3308c69481 class=collapsible-menu></ul></li></ul></div><div class="R-sidebarmenu R-shortcutmenu-shortcuts default-animation"><div class="nav-title padding">More</div><ul class="space collapsible-menu"><li data-nav-url=https://github.com/JustinKennethPearson/ml-1dl034-public-assignments><a class=padding href=https://github.com/JustinKennethPearson/ml-1dl034-public-assignments rel=external><i class='fab fa-fw fa-github'></i> GitHub repo</a></li><li data-nav-url=https://user.it.uu.se/~justin/Hugo/><a class=padding href=https://user.it.uu.se/~justin/Hugo/ rel=external><i class='fas fa-home'></i> Homepage</a></li></ul></div><div id=R-footer-margin class=default-animation></div><div class="R-menu-divider default-animation"><hr class="padding default-animation"></div><div class="R-sidebarmenu R-shortcutmenu-footercontrols default-animation"><ul></ul></div><div id=R-footer class=default-animation><p>Built with <a href=https://github.com/McShelby/hugo-theme-relearn title=love><i class="fas fa-heart"></i></a> by <a href=https://gohugo.io/>Hugo</a></p></div></div></aside><script src=/js/perfect-scrollbar/perfect-scrollbar.min.js?1768643228 defer></script><script src=/js/theme.min.js?1768643228 defer></script><div id=toast-container role=status aria-live=polite aria-atomic=false></div></body></html>