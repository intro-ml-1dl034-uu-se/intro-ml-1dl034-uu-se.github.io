<!doctype html><html lang=en dir=ltr itemscope itemtype=http://schema.org/Article data-r-output-format=html><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.140.2"><meta name=generator content="Relearn 7.3.1"><meta name=description content="Slides Link for the slides.
Today’s Topics: Ensemble Learning Ensemble learning is a simple idea. Instead of training one model, we train multiple models and combine the results. A popular ensemble learning algorithm is random forests that combines many decision trees that are trained on random subsets of the features. To build a classifier a majority vote is taken. There are various techniques to improve the system including boosting, bagging and gradient boosting. As you will see below these are not limited to random forests, but to other combinations of learning algorithms. There is a lot extensions and refinements of ensemble methods including AdaBoost. We will only cover gradient boosting and not go too much into the mathematics behind ensemble learning (that is reserved for a more advanced course). The aim of this lecture is to give you access to another powerful machine learning technique."><meta name=author content="Justin Pearson"><meta name=twitter:card content="summary"><meta name=twitter:title content="Lecture 10: Ensemble Learning :: 1DL034"><meta name=twitter:description content="Slides Link for the slides.
Today’s Topics: Ensemble Learning Ensemble learning is a simple idea. Instead of training one model, we train multiple models and combine the results. A popular ensemble learning algorithm is random forests that combines many decision trees that are trained on random subsets of the features. To build a classifier a majority vote is taken. There are various techniques to improve the system including boosting, bagging and gradient boosting. As you will see below these are not limited to random forests, but to other combinations of learning algorithms. There is a lot extensions and refinements of ensemble methods including AdaBoost. We will only cover gradient boosting and not go too much into the mathematics behind ensemble learning (that is reserved for a more advanced course). The aim of this lecture is to give you access to another powerful machine learning technique."><meta property="og:url" content="https://intro-ml-1dl034-uu-se.github.io/lectures/lecture10/index.html"><meta property="og:site_name" content="1DL034"><meta property="og:title" content="Lecture 10: Ensemble Learning :: 1DL034"><meta property="og:description" content="Slides Link for the slides.
Today’s Topics: Ensemble Learning Ensemble learning is a simple idea. Instead of training one model, we train multiple models and combine the results. A popular ensemble learning algorithm is random forests that combines many decision trees that are trained on random subsets of the features. To build a classifier a majority vote is taken. There are various techniques to improve the system including boosting, bagging and gradient boosting. As you will see below these are not limited to random forests, but to other combinations of learning algorithms. There is a lot extensions and refinements of ensemble methods including AdaBoost. We will only cover gradient boosting and not go too much into the mathematics behind ensemble learning (that is reserved for a more advanced course). The aim of this lecture is to give you access to another powerful machine learning technique."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="Lectures"><meta itemprop=name content="Lecture 10: Ensemble Learning :: 1DL034"><meta itemprop=description content="Slides Link for the slides.
Today’s Topics: Ensemble Learning Ensemble learning is a simple idea. Instead of training one model, we train multiple models and combine the results. A popular ensemble learning algorithm is random forests that combines many decision trees that are trained on random subsets of the features. To build a classifier a majority vote is taken. There are various techniques to improve the system including boosting, bagging and gradient boosting. As you will see below these are not limited to random forests, but to other combinations of learning algorithms. There is a lot extensions and refinements of ensemble methods including AdaBoost. We will only cover gradient boosting and not go too much into the mathematics behind ensemble learning (that is reserved for a more advanced course). The aim of this lecture is to give you access to another powerful machine learning technique."><meta itemprop=wordCount content="459"><title>Lecture 10: Ensemble Learning :: 1DL034</title>
<link href=/lectures/lecture10/index.xml rel=alternate type=application/rss+xml title="Lecture 10: Ensemble Learning :: 1DL034"><link href=/lectures/lecture10/index.print.html rel=alternate type=text/html title="Lecture 10: Ensemble Learning :: 1DL034"><link href=/css/fontawesome-all.min.css?1736242352 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/css/fontawesome-all.min.css?1736242352 rel=stylesheet></noscript><link href=/css/auto-complete.css?1736242352 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/css/auto-complete.css?1736242352 rel=stylesheet></noscript><link href=/css/perfect-scrollbar.min.css?1736242352 rel=stylesheet><link href=/css/theme.min.css?1736242352 rel=stylesheet><link href=/css/format-html.min.css?1736242352 rel=stylesheet id=R-format-style><script>window.relearn=window.relearn||{},window.relearn.relBasePath="../..",window.relearn.relBaseUri="../..",window.relearn.absBaseUri="https://intro-ml-1dl034-uu-se.github.io",window.relearn.min=`.min`,window.relearn.disableAnchorCopy=!1,window.relearn.disableAnchorScrolling=!1,window.relearn.themevariants=["blue"],window.relearn.customvariantname="my-custom-variant",window.relearn.changeVariant=function(e){var t=document.documentElement.dataset.rThemeVariant;window.localStorage.setItem(window.relearn.absBaseUri+"/variant",e),document.documentElement.dataset.rThemeVariant=e,t!=e&&document.dispatchEvent(new CustomEvent("themeVariantLoaded",{detail:{variant:e,oldVariant:t}}))},window.relearn.markVariant=function(){var t=window.localStorage.getItem(window.relearn.absBaseUri+"/variant"),e=document.querySelector("#R-select-variant");e&&(e.value=t)},window.relearn.initVariant=function(){var e=window.localStorage.getItem(window.relearn.absBaseUri+"/variant")??"";e==window.relearn.customvariantname||(!e||!window.relearn.themevariants.includes(e))&&(e=window.relearn.themevariants[0],window.localStorage.setItem(window.relearn.absBaseUri+"/variant",e)),document.documentElement.dataset.rThemeVariant=e},window.relearn.initVariant(),window.relearn.markVariant(),window.T_Copy_to_clipboard=`Copy to clipboard`,window.T_Copied_to_clipboard=`Copied to clipboard!`,window.T_Copy_link_to_clipboard=`Copy link to clipboard`,window.T_Link_copied_to_clipboard=`Copied link to clipboard!`,window.T_Reset_view=`Reset view`,window.T_View_reset=`View reset!`,window.T_No_results_found=`No results found for "{0}"`,window.T_N_results_found=`{1} results found for "{0}"`</script></head><body class="mobile-support html" data-url=/lectures/lecture10/index.html><div id=R-body class=default-animation><div id=R-body-overlay></div><nav id=R-topbar><div class=topbar-wrapper><div class=topbar-sidebar-divider></div><div class="topbar-area topbar-area-start" data-area=start><div class="topbar-button topbar-button-sidebar" data-content-empty=disable data-width-s=show data-width-m=hide data-width-l=hide><button class=topbar-control onclick=toggleNav() type=button title="Menu (CTRL+ALT+n)"><i class="fa-fw fas fa-bars"></i></button></div></div><ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype=http://schema.org/BreadcrumbList><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/index.html><span itemprop=name>Introduction to Machine Learning 1DL034</span></a><meta itemprop=position content="1">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/lectures/index.html><span itemprop=name>Lectures</span></a><meta itemprop=position content="2">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><span itemprop=name>Lecture 10</span><meta itemprop=position content="3"></li></ol><div class="topbar-area topbar-area-end" data-area=end><div class="topbar-button topbar-button-print" data-content-empty=disable data-width-s=area-more data-width-m=show data-width-l=show><a class=topbar-control href=/lectures/lecture10/index.print.html title="Print whole chapter (CTRL+ALT+p)"><i class="fa-fw fas fa-print"></i></a></div><div class="topbar-button topbar-button-more" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><button class=topbar-control onclick=toggleTopbarFlyout(this) type=button title=More><i class="fa-fw fas fa-ellipsis-v"></i></button><div class=topbar-content><div class=topbar-content-wrapper><div class="topbar-area topbar-area-more" data-area=more></div></div></div></div></div></div></nav><div id=R-main-overlay></div><main id=R-body-inner class="highlightable lectures" tabindex=-1><div class=flex-block-wrapper><article class=default><header class=headline></header><h1 id=lecture-10-ensemble-learning>Lecture 10: Ensemble Learning</h1><h2 id=slides>Slides</h2><p>Link for the
<a href=https://user.it.uu.se/~justin/Assets/Teaching/IntroML/Slides/lecture10.pdf rel=external target=_blank>slides.</a></p><h2 id=todays-topics-ensemble-learning>Today&rsquo;s Topics: Ensemble Learning</h2><p>Ensemble learning is a simple idea. Instead of training one model, we
train multiple models and combine the results.
A popular ensemble learning
algorithm is random forests that combines many decision trees that are
trained on random subsets of the features. To build a classifier a
majority vote is taken. There are various techniques to improve the
system including boosting, bagging and gradient boosting. As you will
see below these are not limited to random forests, but to other
combinations of learning algorithms. There is a lot extensions and
refinements of ensemble methods including AdaBoost. We will only
cover gradient boosting and not go too much into the mathematics
behind ensemble learning (that is reserved for a more advanced
course). The aim of this lecture is to give you access to another
powerful machine learning technique.</p><p>One thing that we did not cover in <a href=/lectures/lecture8/index.html>Lecture 8</a> was using decision trees for
regression. Although the idea is not that complicated you should spend
some time understand how Regression trees can be used for
regression. Although you will not be examined on other algorithms for
constructing decisions trees (we covered ID3 in <a href=/lectures/lecture8/index.html>Lecture 8</a> ) you should be aware that
there are other algorithms.</p><p>Constructing the perfect decision tree is
a computationally hard problem (in fact it is NP-complete). For
machine learning we want fast and efficient algorithms for learning,
and most decision tree algorithms in the literature are
approximations.</p><h2 id=reading-guide>Reading Guide</h2><ul><li><p>Chapter 8 of <a href=https://www.bonaccorso.eu/books/ rel=external target=_blank>Machine Learning Algorithms</a>
(Bonaccorso, Giuseppe) <a href=http://tinyurl.com/qsse4vb rel=external target=_blank>online university library
link</a> contains a very good overview of
decision trees and random forests. There are also lots of
scikit-learn code fragments that you can use in your own projects.</p></li><li><p><a href=http://themlbook.com/ rel=external target=_blank>Hundred-Page Machine Learning Book</a> <a href="https://www.dropbox.com/s/qiq2c85cle9ydb6/Chapter3.pdf?dl=0" rel=external target=_blank>Section
3.3</a> is
a good start on decision trees for regression. Again the book does
not really go into much detail on the algorithms, and it only a
starting point. The wikipedia page on
<a href=https://en.wikipedia.org/wiki/Decision_tree_learning rel=external target=_blank>Decision tree
learning</a> is a
good starting point and has many useful references to different
learning algorithms.</p></li><li><p><a href=http://themlbook.com/ rel=external target=_blank>Hundred-Page Machine Learning Book</a>
<a href="https://www.dropbox.com/s/esprbgjm0wc5afz/Chapter7.pdf?dl=0" rel=external target=_blank>Chapter
7.5</a> is
a good start on ensemble methods but does not go into much
detail. As always with the book, if you do not understand the
explanation then start looking at the references.</p></li><li><p><a href=https://www.kaggle.com/prashant111/bagging-vs-boosting rel=external target=_blank>A good Kaggle notebook on Bagging and
Boosting</a></p></li><li><p>To explore more than is covered in the book on gradient boosting you
can start at the <a href=https://en.wikipedia.org/wiki/Gradient_boosting rel=external target=_blank>Wikipedia
page</a> and follow
the references.</p></li><li><p>For your project you should explore scikit-learn
<a href=https://scikit-learn.org/stable/modules/ensemble.html rel=external target=_blank>API</a> on
ensemble methods.</p></li></ul><h2 id=what-should-i-know-by-the-end-of-this-lecture>What should I know by the end of this lecture?</h2><ul><li>How do I use decision trees for regression?</li><li>What is ensemble learning?</li><li>How do random forest work?</li><li>What is boosting and bagging?</li><li>What is gradient boosting?</li></ul><footer class=footline></footer></article></div></main></div><aside id=R-sidebar class=default-animation><div id=R-header-topbar class=default-animation></div><div id=R-header-wrapper class=default-animation><div id=R-header class=default-animation><a id=R-logo class=R-default href=/index.html>1DL034</a></div><script>window.index_js_url="/searchindex.en.js?1736242352"</script><search><form action=/search/index.html method=get><div class="searchbox default-animation"><button class=search-detail type=submit title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
<label class=a11y-only for=R-search-by>Search</label>
<input data-search-input id=R-search-by name=search-by class=search-by type=search placeholder=Search...>
<button class=search-clear type=button data-search-clear title="Clear search"><i class="fas fa-times" title="Clear search"></i></button></div></form></search><script>var contentLangs=["en"]</script><script src=/js/auto-complete.js?1736242352 defer></script><script src=/js/lunr/lunr.min.js?1736242352 defer></script><script src=/js/lunr/lunr.stemmer.support.min.js?1736242352 defer></script><script src=/js/lunr/lunr.multi.min.js?1736242352 defer></script><script src=/js/lunr/lunr.en.min.js?1736242352 defer></script><script src=/js/search.js?1736242352 defer></script></div><div id=R-homelinks class="default-animation homelinks"><ul><li><a class=padding href=/index.html><i class="fa-fw fas fa-home"></i> Home</a></li></ul><hr class=padding></div><div id=R-content-wrapper class=highlightable><div id=R-shortcutmenu-home class=R-sidebarmenu><ul class="enlarge morespace collapsible-menu"><li class=parent data-nav-id=/lectures/index.html><a class=padding href=/lectures/index.html>Lectures</a><ul id=R-subsections-bd2d5f2640929874ad03ea9fdcb748e9 class=collapsible-menu><li data-nav-id=/lectures/lecture1/index.html><a class=padding href=/lectures/lecture1/index.html>Lecture 1</a></li><li data-nav-id=/lectures/lecture2/index.html><a class=padding href=/lectures/lecture2/index.html>Lecture 2</a></li><li class=alwaysopen data-nav-id=/lectures/lecture3/index.html><a class=padding href=/lectures/lecture3/index.html>Lecture 3</a><ul id=R-subsections-169a72b8fc4f8ed04f8294163259b704 class=collapsible-menu></ul></li><li data-nav-id=/lectures/lecture4/index.html><a class=padding href=/lectures/lecture4/index.html>Lecture 4</a></li><li data-nav-id=/lectures/lecture5/index.html><a class=padding href=/lectures/lecture5/index.html>Lecture 5</a></li><li data-nav-id=/lectures/lecture6/index.html><a class=padding href=/lectures/lecture6/index.html>Lecture 6</a></li><li data-nav-id=/lectures/lecture7/index.html><a class=padding href=/lectures/lecture7/index.html>Lecture 7</a></li><li data-nav-id=/lectures/lecture8/index.html><a class=padding href=/lectures/lecture8/index.html>Lecture 8</a></li><li data-nav-id=/lectures/lecture9/index.html><a class=padding href=/lectures/lecture9/index.html>Lecture 9</a></li><li class=active data-nav-id=/lectures/lecture10/index.html><a class=padding href=/lectures/lecture10/index.html>Lecture 10</a></li></ul></li><li data-nav-id=/labs/index.html><a class=padding href=/labs/index.html>Assignments and Project</a></li><li data-nav-id=/resources/index.html><a class=padding href=/resources/index.html>Resources</a><ul id=R-subsections-99e912a437a5f6bb24332b3308c69481 class=collapsible-menu></ul></li></ul></div><div id=R-shortcutmenu-shortcuts class=R-sidebarmenu><div class="nav-title padding">More</div><ul class="space collapsible-menu"><li data-nav-id=https://github.com/JustinKennethPearson/ml-1dl034-public-assignments><a class=padding href=https://github.com/JustinKennethPearson/ml-1dl034-public-assignments target=_blank><i class='fab fa-fw fa-github'></i> GitHub repo</a></li><li data-nav-id=https://user.it.uu.se/~justin/Hugo/><a class=padding href=https://user.it.uu.se/~justin/Hugo/ target=_blank><i class='fas fa-home'></i> Homepage</a></li></ul></div><div class="padding footermargin footerLangSwitch footerVariantSwitch footerVisitedLinks footerFooter showFooter"></div><div id=R-menu-footer><hr class="padding default-animation footerLangSwitch footerVariantSwitch footerVisitedLinks footerFooter showFooter"><div id=R-prefooter class="footerLangSwitch footerVariantSwitch footerVisitedLinks"><ul><li id=R-select-language-container class=footerLangSwitch><div class="padding menu-control"><i class="fa-fw fas fa-language"></i>
<span>&nbsp;</span><div class=control-style><label class=a11y-only for=R-select-language>Language</label>
<select id=R-select-language onchange="location=this.querySelector(this.value).dataset.url"><option id=R-select-language-en value=#R-select-language-en data-url=/lectures/lecture10/index.html lang=en selected></option></select></div><div class=clear></div></div></li><li id=R-select-variant-container class=footerVariantSwitch><div class="padding menu-control"><i class="fa-fw fas fa-paint-brush"></i>
<span>&nbsp;</span><div class=control-style><label class=a11y-only for=R-select-variant>Theme</label>
<select id=R-select-variant onchange=window.relearn.changeVariant(this.value)><option id=R-select-variant-blue value=blue selected>Blue</option></select></div><div class=clear></div></div><script>window.relearn.markVariant()</script></li><li class=footerVisitedLinks><div class="padding menu-control"><i class="fa-fw fas fa-history"></i>
<span>&nbsp;</span><div class=control-style><button onclick=clearHistory()>Clear History</button></div><div class=clear></div></div></li></ul></div><div id=R-footer class="footerFooter showFooter"><p>Built with <a href=https://github.com/McShelby/hugo-theme-relearn title=love><i class="fas fa-heart"></i></a> by <a href=https://gohugo.io/>Hugo</a></p></div></div></div></aside><script src=/js/clipboard.min.js?1736242352 defer></script><script src=/js/perfect-scrollbar.min.js?1736242352 defer></script><script src=/js/theme.js?1736242352 defer></script></body></html>