<!doctype html><html lang=en-uk dir=ltr itemscope itemtype=http://schema.org/Article data-r-output-format=print><head><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.154.5"><meta name=generator content="Relearn 8.3.0+6dafca9f9e6c9639c4a2b886e097505d5ee31955"><meta name=description content="Today’s Topics Linear Regression Linear Regression as a machine learning algorithm. Machine learning algorithms and hypothesises. In short a machine learning find the best hypothesis that explains that data. A cost function (or an error function, or a loss function) measure how far way a hypothesis is from explaining the data: the smaller the cost, the better the hypothesis."><meta name=author content="Justin Pearson"><meta name=twitter:card content="summary"><meta name=twitter:title content="Lecture 2: Linear Regression as Machine Learning :: 1DL034"><meta name=twitter:description content="Today’s Topics Linear Regression Linear Regression as a machine learning algorithm. Machine learning algorithms and hypothesises. In short a machine learning find the best hypothesis that explains that data. A cost function (or an error function, or a loss function) measure how far way a hypothesis is from explaining the data: the smaller the cost, the better the hypothesis."><meta property="og:url" content="https://intro-ml-1dl034-uu-se.github.io/lectures/lecture2/index.html"><meta property="og:site_name" content="1DL034"><meta property="og:title" content="Lecture 2: Linear Regression as Machine Learning :: 1DL034"><meta property="og:description" content="Today’s Topics Linear Regression Linear Regression as a machine learning algorithm. Machine learning algorithms and hypothesises. In short a machine learning find the best hypothesis that explains that data. A cost function (or an error function, or a loss function) measure how far way a hypothesis is from explaining the data: the smaller the cost, the better the hypothesis."><meta property="og:locale" content="en_uk"><meta property="og:type" content="article"><meta property="article:section" content="Lectures"><meta itemprop=name content="Lecture 2: Linear Regression as Machine Learning :: 1DL034"><meta itemprop=description content="Today’s Topics Linear Regression Linear Regression as a machine learning algorithm. Machine learning algorithms and hypothesises. In short a machine learning find the best hypothesis that explains that data. A cost function (or an error function, or a loss function) measure how far way a hypothesis is from explaining the data: the smaller the cost, the better the hypothesis."><meta itemprop=wordCount content="421"><title>Lecture 2: Linear Regression as Machine Learning :: 1DL034</title><link href=https://intro-ml-1dl034-uu-se.github.io/lectures/lecture2/index.html rel=canonical type=text/html title="Lecture 2: Linear Regression as Machine Learning :: 1DL034"><link href=/lectures/lecture2/index.xml rel=alternate type=application/rss+xml title="Lecture 2: Linear Regression as Machine Learning :: 1DL034"><link href=/css/auto-complete/auto-complete.min.css?1769686469 rel=stylesheet><script src=/js/auto-complete/auto-complete.min.js?1769686469 defer></script><script src=/js/search-lunr.min.js?1769686469 defer></script><script src=/js/search.min.js?1769686469 defer></script><script>window.relearn=window.relearn||{},window.relearn.index_js_url="/searchindex.en.js?1769686469"</script><script src=/js/lunr/lunr.min.js?1769686469 defer></script><script src=/js/lunr/lunr.stemmer.support.min.js?1769686469 defer></script><script src=/js/lunr/lunr.multi.min.js?1769686469 defer></script><script src=/js/lunr/lunr.en.min.js?1769686469 defer></script><script>window.relearn=window.relearn||{},window.relearn.contentLangs=["en"]</script><link href=/fonts/fontawesome/css/fontawesome-all.min.css?1769686469 rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/fonts/fontawesome/css/fontawesome-all.min.css?1769686469 rel=stylesheet></noscript><link href=/css/perfect-scrollbar/perfect-scrollbar.min.css?1769686469 rel=stylesheet><link href=/css/theme.min.css?1769686469 rel=stylesheet><link href=/css/format-print.min.css?1769686469 rel=stylesheet id=R-format-style><script>window.relearn=window.relearn||{},window.relearn.min=`.min`,window.relearn.path="/lectures/lecture2/index.html",window.relearn.relBasePath="../..",window.relearn.relBaseUri="../..",window.relearn.absBaseUri="https://intro-ml-1dl034-uu-se.github.io",window.relearn.disableInlineCopyToClipboard=!1,window.relearn.enableBlockCodeWrap=!0,window.relearn.getItem=(e,t)=>e.getItem(t),window.relearn.setItem=(e,t,n)=>e.setItem(t,n),window.relearn.removeItem=(e,t)=>e.removeItem(t),window.T_Copy_to_clipboard=`Copy text to clipboard`,window.T_Copied_to_clipboard=`Text copied to clipboard!`,window.T_Link_copied_to_clipboard=`Link copied to clipboard!`,window.T_Reset_view=`Reset view`,window.T_View_reset=`View reset!`,window.T_No_results_found=`No results found for "{0}"`,window.T_N_results_found=`{1} results found for "{0}"`,window.T_Browser_unsupported_feature=`This browser doesn't support this feature`,window.relearn.themevariants=["blue"],window.relearn.customvariantprefix="my-custom-",window.relearn.changeVariant=function(e){var t=document.documentElement.dataset.rThemeVariant;window.relearn.setItem(window.localStorage,window.relearn.absBaseUri+"/variant",e),document.documentElement.dataset.rThemeVariant=e,t!=e&&(document.dispatchEvent(new CustomEvent("themeVariantLoaded",{detail:{variant:e,oldVariant:t}})),window.relearn.markVariant())},window.relearn.markVariant=function(){var e=window.relearn.getItem(window.localStorage,window.relearn.absBaseUri+"/variant");document.querySelectorAll(".R-variantswitcher select").forEach(t=>{t.value=e})},window.relearn.initVariant=function(){var e=window.relearn.getItem(window.localStorage,window.relearn.absBaseUri+"/variant")??"";(!e||!e.startsWith(window.relearn.customvariantprefix)&&!window.relearn.themevariants.includes(e)||e.startsWith(window.relearn.customvariantprefix)&&!window.relearn.getItem(window.localStorage,window.relearn.absBaseUri+"/variantstylesheet-"+e))&&(e=window.relearn.themevariants[0],window.relearn.setItem(window.localStorage,window.relearn.absBaseUri+"/variant",e)),document.documentElement.dataset.rThemeVariant=e},window.relearn.initVariant(),window.relearn.markVariant()</script></head><body class="mobile-support print" data-url=/lectures/lecture2/index.html><div id=R-body class=default-animation><div id=R-body-overlay></div><nav id=R-topbar class=default-animation><div class="topbar-wrapper default-animation"><div class="topbar-sidebar-divider default-animation"></div><div class="topbar-area topbar-area-start" data-area=start><div class="topbar-button topbar-button-sidebar default-animation" data-content-empty=disable data-width-s=show data-width-m=hide data-width-l=hide><span class="btn cstyle button link noborder notitle interactive"><button onclick=toggleNav() type=button title="Menu (CTRL+ALT+n)"><i class="fa-fw fas fa-bars"></i></button></span></div></div><ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype=http://schema.org/BreadcrumbList><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/index.html><span itemprop=name>Introduction to Machine Learning 1DL034</span></a><meta itemprop=position content="1">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><a itemprop=item href=/lectures/index.html><span itemprop=name>Lectures</span></a><meta itemprop=position content="2">&nbsp;>&nbsp;</li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><span itemprop=name>Lecture 2</span><meta itemprop=position content="3"></li></ol><div class="topbar-area topbar-area-end" data-area=end><div class="topbar-button topbar-button-print default-animation" data-content-empty=disable data-width-s=area-more data-width-m=show data-width-l=show><span class="btn cstyle button link noborder notitle interactive"><a href=/lectures/lecture2/index.print.html title="Print whole chapter (CTRL+ALT+p)"><i class="fa-fw fas fa-print"></i></a></span></div><div class="topbar-button topbar-button-more default-animation" data-content-empty=hide data-width-s=show data-width-m=show data-width-l=show><span class="btn cstyle button link noborder notitle interactive"><button onclick=toggleTopbarFlyout(this) type=button title=More><i class="fa-fw fas fa-ellipsis-v"></i></button></span><div class=topbar-content><div class=topbar-content-wrapper><div class="topbar-area topbar-area-more" data-area=more></div></div></div></div></div></div></nav><div id=R-main-overlay></div><main id=R-body-inner class="highlightable lectures" tabindex=-1><div class=flex-block-wrapper><article class=default><header class=headline></header><h1 id=lecture-2-linear-regression-as-machine-learning>Lecture 2: Linear Regression as Machine Learning</h1><h2 id=todays-topics>Today&rsquo;s Topics<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><h3 id=linear-regression>Linear Regression<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h3><p>Linear Regression as a machine learning algorithm. Machine learning
algorithms and hypothesises. In short a machine learning find the best
hypothesis that explains that data. A cost function (or an error
function, or a loss function) measure how far way a hypothesis is from
explaining the data: the smaller the cost, the better the hypothesis.</p><p>Ideally you want an algorithm takes the training data and gives you
the hypothesis that with the smallest cost value. With linear
regression this is possible (using linear algebra), but in general it
is not possible.</p><p>If you have been reading about neural networks, then in a neural
network the weight roughly corresponds to the set of all possible
hypothesis.</p><h3 id=training-and-test-sets>Training and Test Sets<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h3><p>As the course moves along we will learn more about best practices with
machine learning. The first important idea is that you should split
your data into a test set and a training set. If do not do this then
there is a possibility that you will over fit to your data set, and
when you meet new examples your machine learning system will not
perform that well. It is also important to keep in mind that when you
are using gradient descent to find the best hypothesis you use the
training set, but when you are evaluating the performance of the
learning algorithm you should use the test set. Later on when we look
at cross validation we will look at more advance ways to divide up
your data.</p><h2 id=links-to-slides>Links to Slides<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><ul><li>The slides can be found
<a href=https://user.it.uu.se/~justin/Assets/Teaching/IntroML/Slides/lecture2.pdf rel=external>here.</a>.</li></ul><h2 id=reading-guide>Reading Guide<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><ul><li><a href=http://themlbook.com/ rel=external>Hundred-Page Machine Learning Book</a> <a href="https://www.dropbox.com/s/qiq2c85cle9ydb6/Chapter3.pdf?dl=0" rel=external>Chapter
3</a>
section 3.1 and
<a href="https://www.dropbox.com/s/xpd5x6p6jte3th5/Chapter4.pdf?dl=0" rel=external>Chapter
4</a>.</li><li>Chapter 4 of <a href=https://www.cambridge.org/highereducation/books/a-hands-on-introduction-to-machine-learning/3E57313A963BF7AF5C6330EB88ADAB2E#overview rel=external>A Hands-On Introduction to Machine
Learning</a></li></ul><h2 id=what-should-i-know-by-the-end-of-this-lecture>What should I know by the end of this lecture?<span class="btn cstyle anchor copyanchor scrollanchor link noborder notitle interactive"><button type=button title="Copy link to clipboard"><i class="fa-fw fas fa-link fa-lg"></i></button></span></h2><ul><li>How does linear regression work with one variable?</li><li>How does linear regression work with many variables?</li><li>What is a hypothesis in a machine learning algorithm?</li><li>What is a cost function? Note that in machine learning there is no
standard terminology. This is because machine learning comes from
many different disciplines. Other names for the cost function are
the Error function and the loss function.</li><li>What is the goal of a machine learning algorithm with the hypothesis
and the cost function? What does the cost function measure? Why is a
low value of the cost function desirable?</li><li>How does gradient descent work for linear regression? Can you derive
it from first principles?</li><li>Why is it necessary to split the data up into a training and a test
set?</li></ul><footer class=footline></footer></article></div></main></div><script src=/js/perfect-scrollbar/perfect-scrollbar.min.js?1769686469 defer></script><script src=/js/theme.min.js?1769686469 defer></script><div id=toast-container role=status aria-live=polite aria-atomic=false></div></body></html>